--------------------------------------------------------------------------------------------------------------------------------------------------
      name:  <unnamed>
       log:  C:\Users\rayde\Desktop\uninured.log
  log type:  text
 opened on:   8 Aug 2019, 21:06:34

. 
. use "C:\Users\rayde\Downloads\h196dat\cleaned_data.dta", clear

. 
. ********************************************************************************
. ********************************************************************************
. * Controlling for Cooksd
. ********************************************************************************
. ********************************************************************************
. 
. 
. local list = "regress logit probit"

. 
. cap drop *_uhat* *_yhat*

. 
. foreach x in `list' {
  2. 
. `x' ${depvar} ${model1} ${cooksd}
  3. estimates store `x'_1
  4. predict `x'_uhat1, stdp
  5. predict `x'_yhat1 
  6. 
. `x' ${depvar} ${model2} ${cooksd}
  7. estimates store `x'_2
  8. predict `x'_uhat2, stdp
  9. predict `x'_yhat2 
 10. 
. `x' ${depvar} ${model3} ${cooksd}
 11. estimates store `x'_3
 12. predict `x'_uhat3, stdp
 13. predict `x'_yhat3 
 14. di "==========================================================================="
 15. }
note: mz_wage omitted because of collinearity
note: mz_military omitted because of collinearity

      Source |       SS           df       MS      Number of obs   =     2,551
-------------+----------------------------------   F(4, 2546)      =    157.83
       Model |  126.685499         4  31.6713749   Prob > F        =    0.0000
    Residual |  510.915441     2,546  .200673779   R-squared       =    0.1987
-------------+----------------------------------   Adj R-squared   =    0.1974
       Total |  637.600941     2,550  .250039585   Root MSE        =    .44797

------------------------------------------------------------------------------
        unin |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0001508   .0007956     0.19   0.850    -.0014092    .0017109
        wage |  -.0135755   .0007382   -18.39   0.000    -.0150229    -.012128
    military |  -.2202417    .224514    -0.98   0.327    -.6604903     .220007
        race |  -.1421568   .0103279   -13.76   0.000    -.1624088   -.1219048
     mz_wage |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.015361   .0341737    29.71   0.000     .9483499    1.082372
------------------------------------------------------------------------------
(5,198 missing values generated)
(option xb assumed; fitted values)
(5,198 missing values generated)
note: employed omitted because of collinearity
note: mz_wage omitted because of collinearity
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity

      Source |       SS           df       MS      Number of obs   =     2,551
-------------+----------------------------------   F(4, 2546)      =    157.83
       Model |  126.685499         4  31.6713749   Prob > F        =    0.0000
    Residual |  510.915441     2,546  .200673779   R-squared       =    0.1987
-------------+----------------------------------   Adj R-squared   =    0.1974
       Total |  637.600941     2,550  .250039585   Root MSE        =    .44797

------------------------------------------------------------------------------
        unin |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0001508   .0007956     0.19   0.850    -.0014092    .0017109
        wage |  -.0135755   .0007382   -18.39   0.000    -.0150229    -.012128
    military |  -.2202417    .224514    -0.98   0.327    -.6604903     .220007
        race |  -.1421568   .0103279   -13.76   0.000    -.1624088   -.1219048
    employed |          0  (omitted)
     mz_wage |          0  (omitted)
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.015361   .0341737    29.71   0.000     .9483499    1.082372
------------------------------------------------------------------------------
(5,245 missing values generated)
(option xb assumed; fitted values)
(5,245 missing values generated)
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity

      Source |       SS           df       MS      Number of obs   =     3,838
-------------+----------------------------------   F(4, 3833)      =    102.18
       Model |  91.8752259         4  22.9688065   Prob > F        =    0.0000
    Residual |  861.604972     3,833  .224786061   R-squared       =    0.0964
-------------+----------------------------------   Adj R-squared   =    0.0954
       Total |  953.480198     3,837  .248496273   Root MSE        =    .47412

------------------------------------------------------------------------------
        unin |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0011008   .0006252    -1.76   0.078    -.0023267     .000125
    military |  -.3246677   .2374352    -1.37   0.172    -.7901792    .1408437
        race |  -.1602267   .0084519   -18.96   0.000    -.1767973   -.1436562
    employed |   -.115775   .0163116    -7.10   0.000    -.1477552   -.0837948
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   .9651568   .0303216    31.83   0.000     .9057088    1.024605
------------------------------------------------------------------------------
(2,924 missing values generated)
(option xb assumed; fitted values)
(2,924 missing values generated)
===========================================================================

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_wage omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log likelihood = -1765.0829  
Iteration 1:   log likelihood = -1458.0873  
Iteration 2:   log likelihood = -1445.1271  
Iteration 3:   log likelihood = -1445.0514  
Iteration 4:   log likelihood = -1445.0514  

Logistic regression                             Number of obs     =      2,547
                                                LR chi2(3)        =     640.06
                                                Prob > chi2       =     0.0000
Log likelihood = -1445.0514                     Pseudo R2         =     0.1813

------------------------------------------------------------------------------
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0042912   .0039654     1.08   0.279    -.0034808    .0120631
        wage |  -.1020912   .0064983   -15.71   0.000    -.1148277   -.0893548
    military |          0  (omitted)
        race |  -.7020315   .0546603   -12.84   0.000    -.8091637   -.5948993
     mz_wage |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   2.897114   .1896794    15.27   0.000     2.525349    3.268879
------------------------------------------------------------------------------
(5202 missing values generated)
(option pr assumed; Pr(unin))
(5,202 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: employed omitted because of collinearity
note: mz_wage omitted because of collinearity
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log likelihood = -1765.0829  
Iteration 1:   log likelihood = -1458.0873  
Iteration 2:   log likelihood = -1445.1271  
Iteration 3:   log likelihood = -1445.0514  
Iteration 4:   log likelihood = -1445.0514  

Logistic regression                             Number of obs     =      2,547
                                                LR chi2(3)        =     640.06
                                                Prob > chi2       =     0.0000
Log likelihood = -1445.0514                     Pseudo R2         =     0.1813

------------------------------------------------------------------------------
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0042912   .0039654     1.08   0.279    -.0034808    .0120631
        wage |  -.1020912   .0064983   -15.71   0.000    -.1148277   -.0893548
    military |          0  (omitted)
        race |  -.7020315   .0546603   -12.84   0.000    -.8091637   -.5948993
    employed |          0  (omitted)
     mz_wage |          0  (omitted)
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   2.897114   .1896794    15.27   0.000     2.525349    3.268879
------------------------------------------------------------------------------
(5249 missing values generated)
(option pr assumed; Pr(unin))
(5,249 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log likelihood = -2645.1415  
Iteration 1:   log likelihood = -2453.7702  
Iteration 2:   log likelihood = -2453.7009  
Iteration 3:   log likelihood = -2453.7009  

Logistic regression                             Number of obs     =      3,834
                                                LR chi2(3)        =     382.88
                                                Prob > chi2       =     0.0000
Log likelihood = -2453.7009                     Pseudo R2         =     0.0724

------------------------------------------------------------------------------
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0049463   .0027772    -1.78   0.075    -.0103895    .0004968
    military |          0  (omitted)
        race |    -.71206    .041168   -17.30   0.000    -.7927478   -.6313723
    employed |  -.5181983    .073815    -7.02   0.000     -.662873   -.3735236
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   2.057889   .1422699    14.46   0.000     1.779045    2.336733
------------------------------------------------------------------------------
(2928 missing values generated)
(option pr assumed; Pr(unin))
(2,928 missing values generated)
===========================================================================

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_wage omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log likelihood = -1765.0829  
Iteration 1:   log likelihood = -1456.1445  
Iteration 2:   log likelihood = -1445.5071  
Iteration 3:   log likelihood = -1445.4601  
Iteration 4:   log likelihood = -1445.4601  

Probit regression                               Number of obs     =      2,547
                                                LR chi2(3)        =     639.25
                                                Prob > chi2       =     0.0000
Log likelihood = -1445.4601                     Pseudo R2         =     0.1811

------------------------------------------------------------------------------
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0023023   .0023696     0.97   0.331     -.002342    .0069465
        wage |  -.0597947    .003623   -16.50   0.000    -.0668957   -.0526937
    military |          0  (omitted)
        race |  -.4300924   .0329073   -13.07   0.000    -.4945895   -.3655953
     mz_wage |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.748785   .1113502    15.71   0.000     1.530543    1.967028
------------------------------------------------------------------------------
(5202 missing values generated)
(option pr assumed; Pr(unin))
(5,202 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: employed omitted because of collinearity
note: mz_wage omitted because of collinearity
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log likelihood = -1765.0829  
Iteration 1:   log likelihood = -1456.1445  
Iteration 2:   log likelihood = -1445.5071  
Iteration 3:   log likelihood = -1445.4601  
Iteration 4:   log likelihood = -1445.4601  

Probit regression                               Number of obs     =      2,547
                                                LR chi2(3)        =     639.25
                                                Prob > chi2       =     0.0000
Log likelihood = -1445.4601                     Pseudo R2         =     0.1811

------------------------------------------------------------------------------
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0023023   .0023696     0.97   0.331     -.002342    .0069465
        wage |  -.0597947    .003623   -16.50   0.000    -.0668957   -.0526937
    military |          0  (omitted)
        race |  -.4300924   .0329073   -13.07   0.000    -.4945895   -.3655953
    employed |          0  (omitted)
     mz_wage |          0  (omitted)
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.748785   .1113502    15.71   0.000     1.530543    1.967028
------------------------------------------------------------------------------
(5249 missing values generated)
(option pr assumed; Pr(unin))
(5,249 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log likelihood = -2645.1415  
Iteration 1:   log likelihood = -2452.1122  
Iteration 2:   log likelihood = -2452.0149  
Iteration 3:   log likelihood = -2452.0149  

Probit regression                               Number of obs     =      3,834
                                                LR chi2(3)        =     386.25
                                                Prob > chi2       =     0.0000
Log likelihood = -2452.0149                     Pseudo R2         =     0.0730

------------------------------------------------------------------------------
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0029678   .0016992    -1.75   0.081    -.0062981    .0003625
    military |          0  (omitted)
        race |  -.4446417   .0249411   -17.83   0.000    -.4935254    -.395758
    employed |  -.3143155   .0449125    -7.00   0.000    -.4023424   -.2262886
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.275105   .0856899    14.88   0.000     1.107156    1.443054
------------------------------------------------------------------------------
(2928 missing values generated)
(option pr assumed; Pr(unin))
(2,928 missing values generated)
===========================================================================

. 
. 
. 
. local list = "regress logit probit"

. 
. forval x = 1/3 {
  2. 
.         stderr regress_uhat`x' logit_uhat`x' probit_uhat`x' 
  3.         matrix define stderr`x' = (regress_uhat`x', logit_uhat`x' ,probit_uhat`x' )
  4. 
. }
stderr of regress_uhat1 = 0
stderr of logit_uhat1 = 0
stderr of probit_uhat1 = 0
stderr of regress_uhat2 = 0
stderr of logit_uhat2 = 0
stderr of probit_uhat2 = 0
stderr of regress_uhat3 = 0
stderr of logit_uhat3 = 0
stderr of probit_uhat3 = 0

. 
. matrix stderr = stderr1\stderr2\stderr3

. matrix rownames stderr = stderr1 stderr2 stderr

. matrix colnames stderr =  REGRESS LOGIT PROBIT

. 
. putexcel set "output2.csv", sheet(cooksd) modify

. putexcel A1 = matrix(stderr), names nformat(number_d2)
file output2.csv saved

. 
. 
. capture {

Probit model for unin

              -------- True --------
Classified |         D            ~D  |      Total
-----------+--------------------------+-----------
     +     |      1358           682  |       2040
     -     |       713          1081  |       1794
-----------+--------------------------+-----------
   Total   |      2071          1763  |       3834

Classified + if predicted Pr(D) >= .5
True D defined as unin != 0
--------------------------------------------------
Sensitivity                     Pr( +| D)   65.57%
Specificity                     Pr( -|~D)   61.32%
Positive predictive value       Pr( D| +)   66.57%
Negative predictive value       Pr(~D| -)   60.26%
--------------------------------------------------
False + rate for true ~D        Pr( +|~D)   38.68%
False - rate for true D         Pr( -| D)   34.43%
False + rate for classified +   Pr(~D| +)   33.43%
False - rate for classified -   Pr( D| -)   39.74%
--------------------------------------------------
Correctly classified                        63.62%
--------------------------------------------------

Probit model for unin, goodness-of-fit test

       number of observations =      3834
 number of covariate patterns =       306
            Pearson chi2(302) =      1365.87
                  Prob > chi2 =         0.0000

Probit model for unin, goodness-of-fit test

  (Table collapsed on quantiles of estimated probabilities)

       number of observations =      3834
             number of groups =        10
      Hosmer-Lemeshow chi2(8) =       314.22
                  Prob > chi2 =         0.0000

Probit model for unin, goodness-of-fit test

  (Table collapsed on quantiles of estimated probabilities)
  +--------------------------------------------------------+
  | Group |   Prob | Obs_1 | Exp_1 | Obs_0 | Exp_0 | Total |
  |-------+--------+-------+-------+-------+-------+-------|
  |     1 | 0.3146 |   101 |  92.6 |   283 | 291.4 |   384 |
  |     2 | 0.4447 |   271 | 144.9 |   118 | 244.1 |   389 |
  |     3 | 0.4705 |   163 | 198.5 |   267 | 231.5 |   430 |
  |     4 | 0.4883 |    94 | 163.1 |   245 | 175.9 |   339 |
  |     5 | 0.5072 |   137 | 199.2 |   263 | 200.8 |   400 |
  |-------+--------+-------+-------+-------+-------+-------|
  |     6 | 0.6257 |   195 | 223.4 |   176 | 147.6 |   371 |
  |     7 | 0.6545 |   255 | 262.6 |   153 | 145.4 |   408 |
  |     8 | 0.6675 |   294 | 260.1 |    99 | 132.9 |   393 |
  |     9 | 0.7552 |   260 | 237.2 |    82 | 104.8 |   342 |
  |    10 | 0.7832 |   301 | 291.1 |    77 |  86.9 |   378 |
  +--------------------------------------------------------+

       number of observations =      3834
             number of groups =        10
      Hosmer-Lemeshow chi2(8) =       314.22
                  Prob > chi2 =         0.0000

. 
. foreach x in `list' {
  2. estimates table `x'_1 `x'_2 `x'_3, ///
>   stats(N ll r2_p mrse) b(%7.3f) stfmt(%8.2f)
  3.   
. sum `x'_yhat1 `x'_yhat2 `x'_yhat3
  4. sum `x'_uhat1 `x'_uhat2 `x'_uhat3
  5. 
. }

--------------------------------------------------
    Variable | regress_1   regress_2   regress_3  
-------------+------------------------------------
         age |     0.000       0.000      -0.001  
        wage |    -0.014      -0.014              
    military |    -0.220      -0.220      -0.325  
        race |    -0.142      -0.142      -0.160  
     mz_wage | (omitted)   (omitted)              
 mz_military | (omitted)   (omitted)   (omitted)  
    employed |             (omitted)      -0.116  
 mz_employed |             (omitted)   (omitted)  
       _cons |     1.015       1.015       0.965  
-------------+------------------------------------
           N |      2551        2551        3838  
          ll |  -1568.66    -1568.66    -2579.07  
        r2_p |                                    
        mrse |                                    
--------------------------------------------------

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
regress_yh~1 |      2,694    .4977202    .2257499  -.7069082   .8529768
regress_yh~2 |      2,647    .4966591      .22675  -.7069082   .8529768
regress_yh~3 |      4,968    .5137327    .1719416  -.1613276   .7873165

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
regress_uh~1 |      7,892    .0060128     .010225          0     .22425
regress_uh~2 |      7,892    .0059062    .0101869          0     .22425
regress_uh~3 |      7,892    .0096743    .0095504          0   .2372085

--------------------------------------------------
    Variable |  logit_1     logit_2     logit_3   
-------------+------------------------------------
         age |     0.004       0.004      -0.005  
        wage |    -0.102      -0.102              
    military | (omitted)   (omitted)   (omitted)  
        race |    -0.702      -0.702      -0.712  
     mz_wage | (omitted)   (omitted)              
 mz_military | (omitted)   (omitted)   (omitted)  
    employed |             (omitted)      -0.518  
 mz_employed |             (omitted)   (omitted)  
       _cons |     2.897       2.897       2.058  
-------------+------------------------------------
           N |      2547        2547        3834  
          ll |  -1445.05    -1445.05    -2453.70  
        r2_p |      0.18        0.18        0.07  
        mrse |                                    
--------------------------------------------------

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
 logit_yhat1 |      2,690    .4986627    .2387925   .0002212   .8964007
 logit_yhat2 |      2,643    .4973617    .2396107   .0002212   .8964007
 logit_yhat3 |      4,964    .5153256    .1684344    .090504   .7801753

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
 logit_uhat1 |      7,892    .0346512    .0577157          0   .4683626
 logit_uhat2 |      7,892    .0340956    .0575629          0   .4683626
 logit_uhat3 |      7,892    .0436583    .0373603          0   .1488822

--------------------------------------------------
    Variable | probit_1    probit_2    probit_3   
-------------+------------------------------------
         age |     0.002       0.002      -0.003  
        wage |    -0.060      -0.060              
    military | (omitted)   (omitted)   (omitted)  
        race |    -0.430      -0.430      -0.445  
     mz_wage | (omitted)   (omitted)              
 mz_military | (omitted)   (omitted)   (omitted)  
    employed |             (omitted)      -0.314  
 mz_employed |             (omitted)   (omitted)  
       _cons |     1.749       1.749       1.275  
-------------+------------------------------------
           N |      2547        2547        3834  
          ll |  -1445.46    -1445.46    -2452.01  
        r2_p |      0.18        0.18        0.07  
        mrse |                                    
--------------------------------------------------

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
probit_yhat1 |      2,690     .499044    .2378019   3.44e-07   .9011315
probit_yhat2 |      2,643    .4977729    .2386269   3.44e-07   .9011315
probit_yhat3 |      4,964    .5154453    .1707579   .0757076   .7831802

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
probit_uhat1 |      7,892    .0203011    .0332365          0   .2583421
probit_uhat2 |      7,892     .019969    .0331369          0   .2583421
probit_uhat3 |      7,892    .0266506    .0227305          0   .0908957

. 
. local list = "regress logit probit"

. 
. forval y = 1/3 {
  2. foreach x in `list' {
  3.         
.                 estimates restore `x'_`y'
  4.                 
.                 noisily di "============================================================"
  5.                 noisily di "Model `x'_`y' " e(cmdline)
  6.                 noisily di "============================================================"
  7. 
.                 count if `x'_yhat`y' > .5 & ${depvar}==1 & e(sample)
  8.                 scalar x = r(N)
  9.                 count if ${depvar}==1 & e(sample)
 10.                 scalar y = r(N)
 11.                 scalar z1 = x/y
 12.                 noisily di "Correct Success Prediction Rate: " z1
 13.                 noisily di "predicted =" x ", Actual = " y
 14. 
.                 noisily di "  "
 15. 
.                 count if `x'_yhat`y'<.5 & ${depvar}==0 & e(sample)
 16.                 scalar x = r(N)
 17.                 count if ${depvar}==0 & e(sample) 
 18.                 scalar y = r(N)
 19.                 scalar z2 = x/y
 20.                 noisily di "Correct Failure Prediction Rate: " z2
 21.                 noisily di "predicted =" x ", Actual = " y
 22. 
.                 noisily di " "
 23.                 
.                 count if `x'_yhat`y'> .5 & ${depvar}==0 & e(sample)
 24.                 scalar x = r(N)
 25.                 count if ${depvar}==1 & e(sample)
 26.                 scalar y = r(N)
 27.                 scalar z3 = x/y
 28.                 noisily di "Incorrect Success Prediction Rate: " z3
 29.                 noisily di "predicted =" x ", Actual = " y
 30. 
.                 noisily di " "
 31.                 
.                 count if `x'_yhat`y'<.5 & ${depvar}==1 & e(sample)
 32.                 scalar x = r(N)
 33.                 count if ${depvar}==0 & e(sample)
 34.                 scalar y = r(N)
 35.                 scalar z4 = x/y
 36.                 noisily di "Incorrect Failure Prediction Rate: " z4
 37.                 noisily di "predicted =" x ", Actual = " y
 38.                 matrix define prediction`x'`y' = (z1, z2, z3, z4)
 39. 
. di "==========================================================================="
 40. }
 41. }
(results regress_1 are active now)
============================================================
Model regress_1 regress unin age wage military race mz_wage mz_military if cooksd < 4/_N
============================================================
  940
  1,295
Correct Success Prediction Rate: .72586873
predicted =940, Actual = 1295
  
  785
  1,256
Correct Failure Prediction Rate: .625
predicted =785, Actual = 1256
 
  471
  1,295
Incorrect Success Prediction Rate: .36370656
predicted =471, Actual = 1295
 
  355
  1,256
Incorrect Failure Prediction Rate: .28264331
predicted =355, Actual = 1256
===========================================================================
(results logit_1 are active now)
============================================================
Model logit_1 logit unin age wage military race mz_wage mz_military if cooksd < 4/_N
============================================================
  966
  1,295
Correct Success Prediction Rate: .74594595
predicted =966, Actual = 1295
  
  809
  1,252
Correct Failure Prediction Rate: .64616613
predicted =809, Actual = 1252
 
  443
  1,295
Incorrect Success Prediction Rate: .34208494
predicted =443, Actual = 1295
 
  329
  1,252
Incorrect Failure Prediction Rate: .26277955
predicted =329, Actual = 1252
===========================================================================
(results probit_1 are active now)
============================================================
Model probit_1 probit unin age wage military race mz_wage mz_military if cooksd < 4/_N
============================================================
  967
  1,295
Correct Success Prediction Rate: .74671815
predicted =967, Actual = 1295
  
  809
  1,252
Correct Failure Prediction Rate: .64616613
predicted =809, Actual = 1252
 
  443
  1,295
Incorrect Success Prediction Rate: .34208494
predicted =443, Actual = 1295
 
  328
  1,252
Incorrect Failure Prediction Rate: .26198083
predicted =328, Actual = 1252
===========================================================================
(results regress_2 are active now)
============================================================
Model regress_2 regress unin age wage military race employed mz_wage mz_employed mz_military if cooksd < 4/_N
============================================================
  940
  1,295
Correct Success Prediction Rate: .72586873
predicted =940, Actual = 1295
  
  785
  1,256
Correct Failure Prediction Rate: .625
predicted =785, Actual = 1256
 
  471
  1,295
Incorrect Success Prediction Rate: .36370656
predicted =471, Actual = 1295
 
  355
  1,256
Incorrect Failure Prediction Rate: .28264331
predicted =355, Actual = 1256
===========================================================================
(results logit_2 are active now)
============================================================
Model logit_2 logit unin age wage military race employed mz_wage mz_employed mz_military if cooksd < 4/_N
============================================================
  966
  1,295
Correct Success Prediction Rate: .74594595
predicted =966, Actual = 1295
  
  809
  1,252
Correct Failure Prediction Rate: .64616613
predicted =809, Actual = 1252
 
  443
  1,295
Incorrect Success Prediction Rate: .34208494
predicted =443, Actual = 1295
 
  329
  1,252
Incorrect Failure Prediction Rate: .26277955
predicted =329, Actual = 1252
===========================================================================
(results probit_2 are active now)
============================================================
Model probit_2 probit unin age wage military race employed mz_wage mz_employed mz_military if cooksd < 4/_N
============================================================
  967
  1,295
Correct Success Prediction Rate: .74671815
predicted =967, Actual = 1295
  
  809
  1,252
Correct Failure Prediction Rate: .64616613
predicted =809, Actual = 1252
 
  443
  1,295
Incorrect Success Prediction Rate: .34208494
predicted =443, Actual = 1295
 
  328
  1,252
Incorrect Failure Prediction Rate: .26198083
predicted =328, Actual = 1252
===========================================================================
(results regress_3 are active now)
============================================================
Model regress_3 regress unin age military race employed mz_employed mz_military if cooksd < 4/_N
============================================================
  1,373
  2,071
Correct Success Prediction Rate: .66296475
predicted =1373, Actual = 2071
  
  1,047
  1,767
Correct Failure Prediction Rate: .59252971
predicted =1047, Actual = 1767
 
  720
  2,071
Incorrect Success Prediction Rate: .34765814
predicted =720, Actual = 2071
 
  698
  1,767
Incorrect Failure Prediction Rate: .39501981
predicted =698, Actual = 1767
===========================================================================
(results logit_3 are active now)
============================================================
Model logit_3 logit unin age military race employed mz_employed mz_military if cooksd < 4/_N
============================================================
  1,355
  2,071
Correct Success Prediction Rate: .6542733
predicted =1355, Actual = 2071
  
  1,098
  1,763
Correct Failure Prediction Rate: .62280204
predicted =1098, Actual = 1763
 
  665
  2,071
Incorrect Success Prediction Rate: .32110092
predicted =665, Actual = 2071
 
  716
  1,763
Incorrect Failure Prediction Rate: .40612592
predicted =716, Actual = 1763
===========================================================================
(results probit_3 are active now)
============================================================
Model probit_3 probit unin age military race employed mz_employed mz_military if cooksd < 4/_N
============================================================
  1,358
  2,071
Correct Success Prediction Rate: .65572187
predicted =1358, Actual = 2071
  
  1,081
  1,763
Correct Failure Prediction Rate: .61315939
predicted =1081, Actual = 1763
 
  682
  2,071
Incorrect Success Prediction Rate: .32930951
predicted =682, Actual = 2071
 
  713
  1,763
Incorrect Failure Prediction Rate: .40442428
predicted =713, Actual = 1763
===========================================================================

. 
. 
. 
. 
. forval y = 1/3 {
  2.         matrix accuracy`y' = (predictionregress`y' \ predictionlogit`y' \ predictionprobit`y')
  3.         matrix colnames accuracy`y' = correct_success correct_failure   inaccurate_success inaccurate_failure
  4.         matrix rownames accuracy`x'`y' = REGRESS LOGIT PROBIT
  5.         putexcel set "prediction2.csv", sheet(COOKSD`y') modify
  6.         putexcel A1 = matrix(accuracy`x'`y'), names nformat(number_d2)
  7. 
. }
file prediction2.csv saved
file prediction2.csv saved
file prediction2.csv saved

. 
. 
. ********************************************************************************
. ********************************************************************************
. * 
. * Weighted, Clustered with household id
. *
. ********************************************************************************
. ********************************************************************************
. 
. global option = "[pweight=WGTRU13], vce(cluster DUID)"

. 
. cap drop *_uhat* *_yhat*

. 
. foreach x in `list' {
  2. 
. `x' ${depvar} ${model1} ${option}
  3. estimates store `x'_1
  4. predict `x'_uhat1, stdp
  5. predict `x'_yhat1 
  6. 
. `x' ${depvar} ${model2} ${option}
  7. estimates store `x'_2
  8. predict `x'_uhat2, stdp
  9. predict `x'_yhat2 
 10. 
. `x' ${depvar} ${model3} ${option}
 11. estimates store `x'_3
 12. predict `x'_uhat3, stdp
 13. predict `x'_yhat3 
 14. 
. di "==========================================================================="
 15. }
(sum of wgt is 28,291,582.600795)
note: mz_wage omitted because of collinearity
note: mz_military omitted because of collinearity

Linear regression                               Number of obs     =      2,643
                                                F(4, 818)         =      30.53
                                                Prob > F          =     0.0000
                                                R-squared         =     0.1251
                                                Root MSE          =     .46794

                                 (Std. Err. adjusted for 819 clusters in DUID)
------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0006966   .0022407     0.31   0.756    -.0037017    .0050949
        wage |   -.014197   .0016738    -8.48   0.000    -.0174824   -.0109115
    military |  -.3913568   .0830866    -4.71   0.000    -.5544448   -.2282688
        race |  -.0507434   .0295839    -1.72   0.087    -.1088126    .0073258
     mz_wage |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   .8299703   .0893854     9.29   0.000     .6545185    1.005422
------------------------------------------------------------------------------
(5,198 missing values generated)
(option xb assumed; fitted values)
(5,198 missing values generated)
(sum of wgt is 27,714,085.595549)
note: employed omitted because of collinearity
note: mz_wage omitted because of collinearity
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity

Linear regression                               Number of obs     =      2,596
                                                F(4, 804)         =      30.22
                                                Prob > F          =     0.0000
                                                R-squared         =     0.1256
                                                Root MSE          =     .46771

                                 (Std. Err. adjusted for 805 clusters in DUID)
------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0001243   .0022957     0.05   0.957    -.0043819    .0046305
        wage |  -.0139942   .0016754    -8.35   0.000    -.0172829   -.0107056
    military |  -.3892302   .0836204    -4.65   0.000    -.5533703     -.22509
        race |  -.0525094   .0298672    -1.76   0.079    -.1111362    .0061174
    employed |          0  (omitted)
     mz_wage |          0  (omitted)
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   .8499687   .0912834     9.31   0.000     .6707869    1.029151
------------------------------------------------------------------------------
(5,245 missing values generated)
(option xb assumed; fitted values)
(5,245 missing values generated)
(sum of wgt is 50,330,962.811833)
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity

Linear regression                               Number of obs     =      4,893
                                                F(4, 1433)        =      79.46
                                                Prob > F          =     0.0000
                                                R-squared         =     0.0156
                                                Root MSE          =     .49288

                               (Std. Err. adjusted for 1,434 clusters in DUID)
------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0010734   .0015356    -0.70   0.485    -.0040856    .0019388
    military |  -.5197861   .0358829   -14.49   0.000    -.5901748   -.4493973
        race |  -.0496226   .0198611    -2.50   0.013    -.0885826   -.0106625
    employed |  -.0700777   .0416994    -1.68   0.093    -.1518761    .0117206
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   .7554443   .0754138    10.02   0.000      .607511    .9033776
------------------------------------------------------------------------------
(2,924 missing values generated)
(option xb assumed; fitted values)
(2,924 missing values generated)
===========================================================================

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_wage omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood =  -19577869  
Iteration 1:   log pseudolikelihood =  -17466160  
Iteration 2:   log pseudolikelihood =  -17427786  
Iteration 3:   log pseudolikelihood =  -17427692  
Iteration 4:   log pseudolikelihood =  -17427692  

Logistic regression                             Number of obs     =      2,639
                                                Wald chi2(3)      =      32.60
                                                Prob > chi2       =     0.0000
Log pseudolikelihood =  -17427692               Pseudo R2         =     0.1098

                                 (Std. Err. adjusted for 817 clusters in DUID)
------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0052848   .0102388     0.52   0.606    -.0147829    .0253526
        wage |  -.0861222   .0162101    -5.31   0.000    -.1178934   -.0543511
    military |          0  (omitted)
        race |  -.2347838   .1320945    -1.78   0.076    -.4936844    .0241168
     mz_wage |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.743056   .4342112     4.01   0.000     .8920178    2.594094
------------------------------------------------------------------------------
(5202 missing values generated)
(option pr assumed; Pr(unin))
(5,202 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: employed omitted because of collinearity
note: mz_wage omitted because of collinearity
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood =  -19173086  
Iteration 1:   log pseudolikelihood =  -17098961  
Iteration 2:   log pseudolikelihood =  -17059807  
Iteration 3:   log pseudolikelihood =  -17059713  
Iteration 4:   log pseudolikelihood =  -17059713  

Logistic regression                             Number of obs     =      2,592
                                                Wald chi2(3)      =      32.55
                                                Prob > chi2       =     0.0000
Log pseudolikelihood =  -17059713               Pseudo R2         =     0.1102

                                 (Std. Err. adjusted for 803 clusters in DUID)
------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0025873   .0104752     0.25   0.805    -.0179438    .0231183
        wage |  -.0850113   .0162201    -5.24   0.000    -.1168022   -.0532205
    military |          0  (omitted)
        race |  -.2421501    .133263    -1.82   0.069    -.5033408    .0190406
    employed |          0  (omitted)
     mz_wage |          0  (omitted)
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.834998   .4458189     4.12   0.000     .9612088    2.708787
------------------------------------------------------------------------------
(5249 missing values generated)
(option pr assumed; Pr(unin))
(5,249 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood =  -34511856  
Iteration 1:   log pseudolikelihood =  -34136417  
Iteration 2:   log pseudolikelihood =  -34136282  
Iteration 3:   log pseudolikelihood =  -34136282  

Logistic regression                             Number of obs     =      4,889
                                                Wald chi2(3)      =       8.64
                                                Prob > chi2       =     0.0345
Log pseudolikelihood =  -34136282               Pseudo R2         =     0.0109

                               (Std. Err. adjusted for 1,432 clusters in DUID)
------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0044294   .0063239    -0.70   0.484    -.0168241    .0079653
    military |          0  (omitted)
        race |  -.2027602   .0821347    -2.47   0.014    -.3637413   -.0417792
    employed |  -.2911214   .1757184    -1.66   0.098     -.635523    .0532803
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.048167    .319904     3.28   0.001     .4211664    1.675167
------------------------------------------------------------------------------
(2928 missing values generated)
(option pr assumed; Pr(unin))
(2,928 missing values generated)
===========================================================================

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_wage omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood =  -19577869  
Iteration 1:   log pseudolikelihood =  -17490187  
Iteration 2:   log pseudolikelihood =  -17469565  
Iteration 3:   log pseudolikelihood =  -17469564  

Probit regression                               Number of obs     =      2,639
                                                Wald chi2(3)      =      33.91
                                                Prob > chi2       =     0.0000
Log pseudolikelihood =  -17469564               Pseudo R2         =     0.1077

                                 (Std. Err. adjusted for 817 clusters in DUID)
------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0024136   .0061925     0.39   0.697    -.0097235    .0145507
        wage |  -.0493714   .0092719    -5.32   0.000     -.067544   -.0311988
    military |          0  (omitted)
        race |  -.1437739   .0797355    -1.80   0.071    -.3000525    .0125047
     mz_wage |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.050695   .2599033     4.04   0.000     .5412941    1.560096
------------------------------------------------------------------------------
(5202 missing values generated)
(option pr assumed; Pr(unin))
(5,202 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: employed omitted because of collinearity
note: mz_wage omitted because of collinearity
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood =  -19173086  
Iteration 1:   log pseudolikelihood =  -17119325  
Iteration 2:   log pseudolikelihood =  -17098309  
Iteration 3:   log pseudolikelihood =  -17098308  

Probit regression                               Number of obs     =      2,592
                                                Wald chi2(3)      =      34.23
                                                Prob > chi2       =     0.0000
Log pseudolikelihood =  -17098308               Pseudo R2         =     0.1082

                                 (Std. Err. adjusted for 803 clusters in DUID)
------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0008116   .0063285     0.13   0.898    -.0115922    .0132153
        wage |  -.0487978    .009248    -5.28   0.000    -.0669235    -.030672
    military |          0  (omitted)
        race |  -.1486563   .0805019    -1.85   0.065    -.3064372    .0091247
    employed |          0  (omitted)
     mz_wage |          0  (omitted)
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.107527   .2663135     4.16   0.000     .5855625    1.629492
------------------------------------------------------------------------------
(5249 missing values generated)
(option pr assumed; Pr(unin))
(5,249 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood =  -34511856  
Iteration 1:   log pseudolikelihood =  -34134201  
Iteration 2:   log pseudolikelihood =  -34134148  
Iteration 3:   log pseudolikelihood =  -34134148  

Probit regression                               Number of obs     =      4,889
                                                Wald chi2(3)      =       8.83
                                                Prob > chi2       =     0.0316
Log pseudolikelihood =  -34134148               Pseudo R2         =     0.0109

                               (Std. Err. adjusted for 1,432 clusters in DUID)
------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0027203   .0039136    -0.70   0.487    -.0103908    .0049502
    military |          0  (omitted)
        race |  -.1274258   .0510343    -2.50   0.013    -.2274511   -.0274005
    employed |  -.1808384   .1089393    -1.66   0.097    -.3943555    .0326787
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   .6545675   .1975856     3.31   0.001     .2673069    1.041828
------------------------------------------------------------------------------
(2928 missing values generated)
(option pr assumed; Pr(unin))
(2,928 missing values generated)
===========================================================================

. 
. local list = "regress logit probit"

. 
. forval x = 1/3 {
  2. 
.         stderr regress_uhat`x' logit_uhat`x' probit_uhat`x' 
  3.         matrix define stderr`x' = (regress_uhat`x', logit_uhat`x' ,probit_uhat`x' )
  4. 
. }
stderr of regress_uhat1 = 0
stderr of logit_uhat1 = 0
stderr of probit_uhat1 = 0
stderr of regress_uhat2 = 0
stderr of logit_uhat2 = 0
stderr of probit_uhat2 = 0
stderr of regress_uhat3 = 0
stderr of logit_uhat3 = 0
stderr of probit_uhat3 = 0

. 
. matrix stderr = stderr1\stderr2\stderr3

. matrix rownames stderr = stderr1 stderr2 stderr

. matrix colnames stderr =  REGRESS LOGIT PROBIT

. 
. putexcel set "output2.csv", sheet(wgt_clus) modify

. putexcel A1 = matrix(stderr), names nformat(number_d2)
file output2.csv saved

. 
. 
. capture {
pweights not allowed

. 
. foreach x in `list' {
  2.         estimates table `x'_1 `x'_2 `x'_3 , ///
>           stats(N ll r2_p mrse) b(%7.3f) stfmt(%8.2f)
  3.           
.         sum `x'_yhat1 `x'_yhat2 `x'_yhat3 ${depvar}
  4.         
.         sum `x'_uhat1 `x'_uhat2 `x'_uhat3 ${depvar}
  5. }

--------------------------------------------------
    Variable | regress_1   regress_2   regress_3  
-------------+------------------------------------
         age |     0.001       0.000      -0.001  
        wage |    -0.014      -0.014              
    military |    -0.391      -0.389      -0.520  
        race |    -0.051      -0.053      -0.050  
     mz_wage | (omitted)   (omitted)              
 mz_military | (omitted)   (omitted)   (omitted)  
    employed |             (omitted)      -0.070  
 mz_employed |             (omitted)   (omitted)  
       _cons |     0.830       0.850       0.755  
-------------+------------------------------------
           N |      2643        2596        4893  
          ll |  -1740.61    -1708.35    -3478.64  
        r2_p |                                    
        mrse |                                    
--------------------------------------------------

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
regress_yh~1 |      2,694    .5014359    .1848405  -.5503601   .7782461
regress_yh~2 |      2,647    .4991161    .1856522   -.550984    .775766
regress_yh~3 |      4,968    .5639081    .0632947  -.0769195   .6886472
        unin |      7,892          .5    .5000317          0          1

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
regress_uh~1 |      7,892    .0158346    .0238929          0   .1147797
regress_uh~2 |      7,892    .0157495    .0240589          0   .1146591
regress_uh~3 |      7,892    .0231246    .0195991          0   .0739531
        unin |      7,892          .5    .5000317          0          1

--------------------------------------------------
    Variable |  logit_1     logit_2     logit_3   
-------------+------------------------------------
         age |     0.005       0.003      -0.004  
        wage |    -0.086      -0.085              
    military | (omitted)   (omitted)   (omitted)  
        race |    -0.235      -0.242      -0.203  
     mz_wage | (omitted)   (omitted)              
 mz_military | (omitted)   (omitted)   (omitted)  
    employed |             (omitted)      -0.291  
 mz_employed |             (omitted)   (omitted)  
       _cons |     1.743       1.835       1.048  
-------------+------------------------------------
           N |      2639        2592        4889  
          ll |  -1.7e+07    -1.7e+07    -3.4e+07  
        r2_p |      0.11        0.11        0.01  
        mrse |                                    
--------------------------------------------------

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
 logit_yhat1 |      2,690    .5088499    .1848709    .001868   .8244503
 logit_yhat2 |      2,643    .5065999    .1856427   .0018902   .8206033
 logit_yhat3 |      4,964     .564354    .0609607   .3743353   .6845012
        unin |      7,892          .5    .5000317          0          1

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
 logit_uhat1 |      7,892    .0847905    .1417898          0   1.140506
 logit_uhat2 |      7,892    .0843651    .1425068          0   1.142808
 logit_uhat3 |      7,892    .0957522    .0814927          0   .3026262
        unin |      7,892          .5    .5000317          0          1

--------------------------------------------------
    Variable | probit_1    probit_2    probit_3   
-------------+------------------------------------
         age |     0.002       0.001      -0.003  
        wage |    -0.049      -0.049              
    military | (omitted)   (omitted)   (omitted)  
        race |    -0.144      -0.149      -0.127  
     mz_wage | (omitted)   (omitted)              
 mz_military | (omitted)   (omitted)   (omitted)  
    employed |             (omitted)      -0.181  
 mz_employed |             (omitted)   (omitted)  
       _cons |     1.051       1.108       0.655  
-------------+------------------------------------
           N |      2639        2592        4889  
          ll |  -1.7e+07    -1.7e+07    -3.4e+07  
        r2_p |      0.11        0.11        0.01  
        mrse |                                    
--------------------------------------------------

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
probit_yhat1 |      2,690    .5094617    .1798168   .0001477   .8167719
probit_yhat2 |      2,643    .5072478    .1808791   .0001477    .814188
probit_yhat3 |      4,964    .5646785    .0612066    .374038   .6856711
        unin |      7,892          .5    .5000317          0          1

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
probit_uhat1 |      7,892    .0504125    .0829208          0   .6457995
probit_uhat2 |      7,892    .0500973    .0831935          0   .6449722
probit_uhat3 |      7,892    .0594867    .0505121          0   .1870465
        unin |      7,892          .5    .5000317          0          1

. 
. local list = "regress logit probit"

. 
. forval y = 1/3 {
  2. foreach x in `list' {
  3.         
.                 estimates restore `x'_`y'
  4.                 
.                 noisily di "============================================================"
  5.                 noisily di "Model `x'_`y' " e(cmdline)
  6.                 noisily di "============================================================"
  7. 
.                 count if `x'_yhat`y' > .5 & ${depvar}==1 & e(sample)
  8.                 scalar x = r(N)
  9.                 count if ${depvar}==1 & e(sample)
 10.                 scalar y = r(N)
 11.                 scalar z1 = x/y
 12.                 noisily di "Correct Success Prediction Rate: " z1
 13.                 noisily di "predicted =" x ", Actual = " y
 14. 
.                 noisily di "  "
 15. 
.                 count if `x'_yhat`y'<.5 & ${depvar}==0 & e(sample)
 16.                 scalar x = r(N)
 17.                 count if ${depvar}==0 & e(sample) 
 18.                 scalar y = r(N)
 19.                 scalar z2 = x/y
 20.                 noisily di "Correct Failure Prediction Rate: " z2
 21.                 noisily di "predicted =" x ", Actual = " y
 22. 
.                 noisily di " "
 23.                 
.                 count if `x'_yhat`y'> .5 & ${depvar}==0 & e(sample)
 24.                 scalar x = r(N)
 25.                 count if ${depvar}==1 & e(sample)
 26.                 scalar y = r(N)
 27.                 scalar z3 = x/y
 28.                 noisily di "Incorrect Success Prediction Rate: " z3
 29.                 noisily di "predicted =" x ", Actual = " y
 30. 
.                 noisily di " "
 31.                 
.                 count if `x'_yhat`y'<.5 & ${depvar}==1 & e(sample)
 32.                 scalar x = r(N)
 33.                 count if ${depvar}==0 & e(sample)
 34.                 scalar y = r(N)
 35.                 scalar z4 = x/y
 36.                 noisily di "Incorrect Failure Prediction Rate: " z4
 37.                 noisily di "predicted =" x ", Actual = " y
 38.                 matrix define prediction`x'`y' = (z1, z2, z3, z4)
 39. 
. di "==========================================================================="
 40. }
 41. }
(results regress_1 are active now)
============================================================
Model regress_1 regress unin age wage military race mz_wage mz_military [pweight=WGTRU13], vce(cluster DUID)
============================================================
  1,116
  1,393
Correct Success Prediction Rate: .8011486
predicted =1116, Actual = 1393
  
  715
  1,250
Correct Failure Prediction Rate: .572
predicted =715, Actual = 1250
 
  535
  1,393
Incorrect Success Prediction Rate: .38406317
predicted =535, Actual = 1393
 
  277
  1,250
Incorrect Failure Prediction Rate: .2216
predicted =277, Actual = 1250
===========================================================================
(results logit_1 are active now)
============================================================
Model logit_1 logit unin age wage military race mz_wage mz_military [pweight=WGTRU13], vce(cluster DUID)
============================================================
  1,068
  1,393
Correct Success Prediction Rate: .7666906
predicted =1068, Actual = 1393
  
  736
  1,246
Correct Failure Prediction Rate: .59069021
predicted =736, Actual = 1246
 
  510
  1,393
Incorrect Success Prediction Rate: .3661163
predicted =510, Actual = 1393
 
  325
  1,246
Incorrect Failure Prediction Rate: .26083467
predicted =325, Actual = 1246
===========================================================================
(results probit_1 are active now)
============================================================
Model probit_1 probit unin age wage military race mz_wage mz_military [pweight=WGTRU13], vce(cluster DUID)
============================================================
  1,085
  1,393
Correct Success Prediction Rate: .77889447
predicted =1085, Actual = 1393
  
  727
  1,246
Correct Failure Prediction Rate: .58346709
predicted =727, Actual = 1246
 
  519
  1,393
Incorrect Success Prediction Rate: .37257717
predicted =519, Actual = 1393
 
  308
  1,246
Incorrect Failure Prediction Rate: .24719101
predicted =308, Actual = 1246
===========================================================================
(results regress_2 are active now)
============================================================
Model regress_2 regress unin age wage military race employed mz_wage mz_employed mz_military [pweight=WGTRU13], vce(cluster DUID)
============================================================
  1,069
  1,358
Correct Success Prediction Rate: .78718704
predicted =1069, Actual = 1358
  
  721
  1,238
Correct Failure Prediction Rate: .58239095
predicted =721, Actual = 1238
 
  517
  1,358
Incorrect Success Prediction Rate: .38070692
predicted =517, Actual = 1358
 
  289
  1,238
Incorrect Failure Prediction Rate: .23344103
predicted =289, Actual = 1238
===========================================================================
(results logit_2 are active now)
============================================================
Model logit_2 logit unin age wage military race employed mz_wage mz_employed mz_military [pweight=WGTRU13], vce(cluster DUID)
============================================================
  1,025
  1,358
Correct Success Prediction Rate: .75478645
predicted =1025, Actual = 1358
  
  735
  1,234
Correct Failure Prediction Rate: .59562399
predicted =735, Actual = 1234
 
  499
  1,358
Incorrect Success Prediction Rate: .36745214
predicted =499, Actual = 1358
 
  333
  1,234
Incorrect Failure Prediction Rate: .26985413
predicted =333, Actual = 1234
===========================================================================
(results probit_2 are active now)
============================================================
Model probit_2 probit unin age wage military race employed mz_wage mz_employed mz_military [pweight=WGTRU13], vce(cluster DUID)
============================================================
  1,060
  1,358
Correct Success Prediction Rate: .78055965
predicted =1060, Actual = 1358
  
  723
  1,234
Correct Failure Prediction Rate: .58589951
predicted =723, Actual = 1234
 
  511
  1,358
Incorrect Success Prediction Rate: .37628866
predicted =511, Actual = 1358
 
  298
  1,234
Incorrect Failure Prediction Rate: .24149109
predicted =298, Actual = 1234
===========================================================================
(results regress_3 are active now)
============================================================
Model regress_3 regress unin age military race employed mz_employed mz_military [pweight=WGTRU13], vce(cluster DUID)
============================================================
  2,542
  2,906
Correct Success Prediction Rate: .87474191
predicted =2542, Actual = 2906
  
  333
  1,987
Correct Failure Prediction Rate: .16758933
predicted =333, Actual = 1987
 
  1,654
  2,906
Incorrect Success Prediction Rate: .56916724
predicted =1654, Actual = 2906
 
  364
  1,987
Incorrect Failure Prediction Rate: .18319074
predicted =364, Actual = 1987
===========================================================================
(results logit_3 are active now)
============================================================
Model logit_3 logit unin age military race employed mz_employed mz_military [pweight=WGTRU13], vce(cluster DUID)
============================================================
  2,535
  2,906
Correct Success Prediction Rate: .8723331
predicted =2535, Actual = 2906
  
  334
  1,983
Correct Failure Prediction Rate: .16843167
predicted =334, Actual = 1983
 
  1,649
  2,906
Incorrect Success Prediction Rate: .56744666
predicted =1649, Actual = 2906
 
  371
  1,983
Incorrect Failure Prediction Rate: .18709027
predicted =371, Actual = 1983
===========================================================================
(results probit_3 are active now)
============================================================
Model probit_3 probit unin age military race employed mz_employed mz_military [pweight=WGTRU13], vce(cluster DUID)
============================================================
  2,535
  2,906
Correct Success Prediction Rate: .8723331
predicted =2535, Actual = 2906
  
  334
  1,983
Correct Failure Prediction Rate: .16843167
predicted =334, Actual = 1983
 
  1,649
  2,906
Incorrect Success Prediction Rate: .56744666
predicted =1649, Actual = 2906
 
  371
  1,983
Incorrect Failure Prediction Rate: .18709027
predicted =371, Actual = 1983
===========================================================================

. 
. 
. forval y = 1/3 {
  2. 
.         matrix accuracy`y' = (predictionregress`y' \ predictionlogit`y' \ predictionprobit`y')
  3.         matrix colnames accuracy`y' = correct_success correct_failure   inaccurate_success inaccurate_failure
  4.         matrix rownames accuracy`x'`y' = REGRESS LOGIT PROBIT
  5.         putexcel set "prediction2.csv", sheet(WGT_CLUS_`y') modify
  6.         putexcel A1 = matrix(accuracy`x'`y'), names nformat(number_d2)
  7. 
. }
file prediction2.csv saved
file prediction2.csv saved
file prediction2.csv saved

. 
. 
. ********************************************************************************
. ********************************************************************************
. * 
. * Weighted Only
. *
. ********************************************************************************
. ********************************************************************************
. 
. cap drop *uhat* *_yhat*

. global option = "[pweight=WGTRU13]"

. 
. local list = "regress logit probit"

. 
. foreach x in `list' {
  2. 
. `x' ${depvar} ${model1} ${option}
  3. estimates store `x'_1
  4. predict `x'_uhat1, stdp
  5. predict `x'_yhat1 
  6. 
. `x' ${depvar} ${model2} ${option}
  7. estimates store `x'_2
  8. predict `x'_uhat2, stdp
  9. predict `x'_yhat2 
 10. 
. `x' ${depvar} ${model3} ${option}
 11. estimates store `x'_3
 12. predict `x'_uhat3, stdp
 13. predict `x'_yhat3 
 14. di "==========================================================================="
 15. }
(sum of wgt is 28,291,582.600795)
note: mz_wage omitted because of collinearity
note: mz_military omitted because of collinearity

Linear regression                               Number of obs     =      2,643
                                                F(4, 2638)        =     103.36
                                                Prob > F          =     0.0000
                                                R-squared         =     0.1251
                                                Root MSE          =     .46794

------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0006966    .001027     0.68   0.498    -.0013172    .0027105
        wage |   -.014197   .0008497   -16.71   0.000    -.0158631   -.0125308
    military |  -.3913568   .0565061    -6.93   0.000    -.5021576    -.280556
        race |  -.0507434   .0117424    -4.32   0.000    -.0737687   -.0277181
     mz_wage |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   .8299703   .0422582    19.64   0.000     .7471076     .912833
------------------------------------------------------------------------------
(5,198 missing values generated)
(option xb assumed; fitted values)
(5,198 missing values generated)
(sum of wgt is 27,714,085.595549)
note: employed omitted because of collinearity
note: mz_wage omitted because of collinearity
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity

Linear regression                               Number of obs     =      2,596
                                                F(4, 2591)        =     103.00
                                                Prob > F          =     0.0000
                                                R-squared         =     0.1256
                                                Root MSE          =     .46771

------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0001243   .0010476     0.12   0.906      -.00193    .0021786
        wage |  -.0139942   .0008484   -16.50   0.000    -.0156578   -.0123307
    military |  -.3892302   .0568502    -6.85   0.000    -.5007067   -.2777537
        race |  -.0525094   .0118379    -4.44   0.000    -.0757221   -.0292967
    employed |          0  (omitted)
     mz_wage |          0  (omitted)
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   .8499687   .0430124    19.76   0.000     .7656265     .934311
------------------------------------------------------------------------------
(5,245 missing values generated)
(option xb assumed; fitted values)
(5,245 missing values generated)
(sum of wgt is 50,330,962.811833)
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity

Linear regression                               Number of obs     =      4,893
                                                F(4, 4888)        =     204.55
                                                Prob > F          =     0.0000
                                                R-squared         =     0.0156
                                                Root MSE          =     .49288

------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0010734   .0007053    -1.52   0.128     -.002456    .0003092
    military |  -.5197861   .0215894   -24.08   0.000    -.5621111   -.4774611
        race |  -.0496226   .0082967    -5.98   0.000    -.0658879   -.0333573
    employed |  -.0700777   .0188053    -3.73   0.000    -.1069446   -.0332109
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   .7554443   .0336655    22.44   0.000     .6894448    .8214438
------------------------------------------------------------------------------
(2,924 missing values generated)
(option xb assumed; fitted values)
(2,924 missing values generated)
===========================================================================

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_wage omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood =  -19577869  
Iteration 1:   log pseudolikelihood =  -17466160  
Iteration 2:   log pseudolikelihood =  -17427786  
Iteration 3:   log pseudolikelihood =  -17427692  
Iteration 4:   log pseudolikelihood =  -17427692  

Logistic regression                             Number of obs     =      2,639
                                                Wald chi2(3)      =     123.43
                                                Prob > chi2       =     0.0000
Log pseudolikelihood =  -17427692               Pseudo R2         =     0.1098

------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0052848   .0046787     1.13   0.259    -.0038852    .0144548
        wage |  -.0861222    .008489   -10.15   0.000    -.1027604   -.0694841
    military |          0  (omitted)
        race |  -.2347838   .0523717    -4.48   0.000    -.3374305   -.1321371
     mz_wage |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.743056   .2089807     8.34   0.000     1.333462    2.152651
------------------------------------------------------------------------------
(5202 missing values generated)
(option pr assumed; Pr(unin))
(5,202 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: employed omitted because of collinearity
note: mz_wage omitted because of collinearity
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood =  -19173086  
Iteration 1:   log pseudolikelihood =  -17098961  
Iteration 2:   log pseudolikelihood =  -17059807  
Iteration 3:   log pseudolikelihood =  -17059713  
Iteration 4:   log pseudolikelihood =  -17059713  

Logistic regression                             Number of obs     =      2,592
                                                Wald chi2(3)      =     123.98
                                                Prob > chi2       =     0.0000
Log pseudolikelihood =  -17059713               Pseudo R2         =     0.1102

------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0025873   .0047669     0.54   0.587    -.0067557    .0119303
        wage |  -.0850113   .0084893   -10.01   0.000    -.1016501   -.0683726
    military |          0  (omitted)
        race |  -.2421501   .0527673    -4.59   0.000    -.3455721   -.1387281
    employed |          0  (omitted)
     mz_wage |          0  (omitted)
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.834998   .2140346     8.57   0.000     1.415498    2.254498
------------------------------------------------------------------------------
(5249 missing values generated)
(option pr assumed; Pr(unin))
(5,249 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood =  -34511856  
Iteration 1:   log pseudolikelihood =  -34136417  
Iteration 2:   log pseudolikelihood =  -34136282  
Iteration 3:   log pseudolikelihood =  -34136282  

Logistic regression                             Number of obs     =      4,889
                                                Wald chi2(3)      =      48.56
                                                Prob > chi2       =     0.0000
Log pseudolikelihood =  -34136282               Pseudo R2         =     0.0109

------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0044294   .0029045    -1.53   0.127    -.0101221    .0012632
    military |          0  (omitted)
        race |  -.2027602    .034295    -5.91   0.000    -.2699773   -.1355432
    employed |  -.2911214   .0790897    -3.68   0.000    -.4461344   -.1361083
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.048167   .1426392     7.35   0.000     .7685991    1.327734
------------------------------------------------------------------------------
(2928 missing values generated)
(option pr assumed; Pr(unin))
(2,928 missing values generated)
===========================================================================

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_wage omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood =  -19577869  
Iteration 1:   log pseudolikelihood =  -17490187  
Iteration 2:   log pseudolikelihood =  -17469565  
Iteration 3:   log pseudolikelihood =  -17469564  

Probit regression                               Number of obs     =      2,639
                                                Wald chi2(3)      =     123.48
                                                Prob > chi2       =     0.0000
Log pseudolikelihood =  -17469564               Pseudo R2         =     0.1077

------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0024136   .0028767     0.84   0.401    -.0032247    .0080519
        wage |  -.0493714   .0050015    -9.87   0.000    -.0591742   -.0395686
    military |          0  (omitted)
        race |  -.1437739    .031751    -4.53   0.000    -.2060048    -.081543
     mz_wage |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.050695   .1248019     8.42   0.000      .806088    1.295302
------------------------------------------------------------------------------
(5202 missing values generated)
(option pr assumed; Pr(unin))
(5,202 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: employed omitted because of collinearity
note: mz_wage omitted because of collinearity
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood =  -19173086  
Iteration 1:   log pseudolikelihood =  -17119325  
Iteration 2:   log pseudolikelihood =  -17098309  
Iteration 3:   log pseudolikelihood =  -17098308  

Probit regression                               Number of obs     =      2,592
                                                Wald chi2(3)      =     125.88
                                                Prob > chi2       =     0.0000
Log pseudolikelihood =  -17098308               Pseudo R2         =     0.1082

------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0008116   .0029272     0.28   0.782    -.0049257    .0065488
        wage |  -.0487978   .0049797    -9.80   0.000    -.0585579   -.0390377
    military |          0  (omitted)
        race |  -.1486563   .0320195    -4.64   0.000    -.2114134   -.0858992
    employed |          0  (omitted)
     mz_wage |          0  (omitted)
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.107527   .1275281     8.68   0.000     .8575769    1.357478
------------------------------------------------------------------------------
(5249 missing values generated)
(option pr assumed; Pr(unin))
(5,249 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood =  -34511856  
Iteration 1:   log pseudolikelihood =  -34134201  
Iteration 2:   log pseudolikelihood =  -34134148  
Iteration 3:   log pseudolikelihood =  -34134148  

Probit regression                               Number of obs     =      4,889
                                                Wald chi2(3)      =      49.75
                                                Prob > chi2       =     0.0000
Log pseudolikelihood =  -34134148               Pseudo R2         =     0.0109

------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0027203   .0017963    -1.51   0.130    -.0062411    .0008005
    military |          0  (omitted)
        race |  -.1274258   .0213145    -5.98   0.000    -.1692015   -.0856501
    employed |  -.1808384   .0490411    -3.69   0.000    -.2769571   -.0847197
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   .6545675    .087976     7.44   0.000     .4821377    .8269972
------------------------------------------------------------------------------
(2928 missing values generated)
(option pr assumed; Pr(unin))
(2,928 missing values generated)
===========================================================================

. 
. local list = "regress logit probit"

. 
. forval x = 1/3 {
  2. 
.         stderr regress_uhat`x' logit_uhat`x' probit_uhat`x' 
  3.         matrix define stderr`x' = (regress_uhat`x', logit_uhat`x' ,probit_uhat`x' )
  4. 
. }
stderr of regress_uhat1 = 0
stderr of logit_uhat1 = 0
stderr of probit_uhat1 = 0
stderr of regress_uhat2 = 0
stderr of logit_uhat2 = 0
stderr of probit_uhat2 = 0
stderr of regress_uhat3 = 0
stderr of logit_uhat3 = 0
stderr of probit_uhat3 = 0

. 
. matrix stderr = stderr1\stderr2\stderr3

. matrix rownames stderr = stderr1 stderr2 stderr3

. matrix colnames stderr =  REGRESS LOGIT PROBIT

. 
. putexcel set "output2.csv", sheet(weighted) modify

. putexcel A1 = matrix(stderr), names nformat(number_d2)
file output2.csv saved

. 
.  
. capture {
pweights not allowed

. 
. local list = "regress logit probit"

. foreach x in `list' {
  2.         estimates table `x'_1 `x'_2 `x'_3, ///
>           stats(N ll r2_p mrse) b(%7.3f) stfmt(%8.2f)
  3.           
.         sum `x'_yhat1 `x'_yhat2 `x'_yhat3 ${depvar}
  4.         
.         sum `x'_uhat1 `x'_uhat2 `x'_uhat3 
  5.         di "==========================================================================="
  6. }

--------------------------------------------------
    Variable | regress_1   regress_2   regress_3  
-------------+------------------------------------
         age |     0.001       0.000      -0.001  
        wage |    -0.014      -0.014              
    military |    -0.391      -0.389      -0.520  
        race |    -0.051      -0.053      -0.050  
     mz_wage | (omitted)   (omitted)              
 mz_military | (omitted)   (omitted)   (omitted)  
    employed |             (omitted)      -0.070  
 mz_employed |             (omitted)   (omitted)  
       _cons |     0.830       0.850       0.755  
-------------+------------------------------------
           N |      2643        2596        4893  
          ll |  -1740.61    -1708.35    -3478.64  
        r2_p |                                    
        mrse |                                    
--------------------------------------------------

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
regress_yh~1 |      2,694    .5014359    .1848405  -.5503601   .7782461
regress_yh~2 |      2,647    .4991161    .1856522   -.550984    .775766
regress_yh~3 |      4,968    .5639081    .0632947  -.0769195   .6886472
        unin |      7,892          .5    .5000317          0          1

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
regress_uh~1 |      7,892    .0071461    .0107393          0   .0582691
regress_uh~2 |      7,892    .0070912    .0107879          0   .0586099
regress_uh~3 |      7,892    .0103827    .0086665          0    .032291
===========================================================================

--------------------------------------------------
    Variable |  logit_1     logit_2     logit_3   
-------------+------------------------------------
         age |     0.005       0.003      -0.004  
        wage |    -0.086      -0.085              
    military | (omitted)   (omitted)   (omitted)  
        race |    -0.235      -0.242      -0.203  
     mz_wage | (omitted)   (omitted)              
 mz_military | (omitted)   (omitted)   (omitted)  
    employed |             (omitted)      -0.291  
 mz_employed |             (omitted)   (omitted)  
       _cons |     1.743       1.835       1.048  
-------------+------------------------------------
           N |      2639        2592        4889  
          ll |  -1.7e+07    -1.7e+07    -3.4e+07  
        r2_p |      0.11        0.11        0.01  
        mrse |                                    
--------------------------------------------------

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
 logit_yhat1 |      2,690    .5088499    .1848709    .001868   .8244503
 logit_yhat2 |      2,643    .5065999    .1856427   .0018902   .8206033
 logit_yhat3 |      4,964     .564354    .0609607   .3743353   .6845012
        unin |      7,892          .5    .5000317          0          1

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
 logit_uhat1 |      7,892    .0397267    .0690475          0   .5950812
 logit_uhat2 |      7,892    .0394678    .0692838          0   .5960151
 logit_uhat3 |      7,892     .042952    .0359988          0    .132462
===========================================================================

--------------------------------------------------
    Variable | probit_1    probit_2    probit_3   
-------------+------------------------------------
         age |     0.002       0.001      -0.003  
        wage |    -0.049      -0.049              
    military | (omitted)   (omitted)   (omitted)  
        race |    -0.144      -0.149      -0.127  
     mz_wage | (omitted)   (omitted)              
 mz_military | (omitted)   (omitted)   (omitted)  
    employed |             (omitted)      -0.181  
 mz_employed |             (omitted)   (omitted)  
       _cons |     1.051       1.108       0.655  
-------------+------------------------------------
           N |      2639        2592        4889  
          ll |  -1.7e+07    -1.7e+07    -3.4e+07  
        r2_p |      0.11        0.11        0.01  
        mrse |                                    
--------------------------------------------------

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
probit_yhat1 |      2,690    .5094617    .1798168   .0001477   .8167719
probit_yhat2 |      2,643    .5072478    .1808791   .0001477    .814188
probit_yhat3 |      4,964    .5646785    .0612066    .374038   .6856711
        unin |      7,892          .5    .5000317          0          1

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
probit_uhat1 |      7,892    .0238683    .0409311          0    .347038
probit_uhat2 |      7,892    .0236678    .0409479          0   .3453345
probit_uhat3 |      7,892    .0266814    .0223122          0   .0822815
===========================================================================

. 
. local list = "regress logit probit"

. 
. forval y = 1/3 {
  2. foreach x in `list' {
  3.         
.                 estimates restore `x'_`y'
  4.                 
.                 noisily di "============================================================"
  5.                 noisily di "Model `x'_`y' " e(cmdline)
  6.                 noisily di "============================================================"
  7. 
.                 count if `x'_yhat`y' > .5 & ${depvar}==1 & e(sample)
  8.                 scalar x = r(N)
  9.                 count if ${depvar}==1 & e(sample)
 10.                 scalar y = r(N)
 11.                 scalar z1 = x/y
 12.                 noisily di "Correct Success Prediction Rate: " z1
 13.                 noisily di "predicted =" x ", Actual = " y
 14. 
.                 noisily di "  "
 15. 
.                 count if `x'_yhat`y'<.5 & ${depvar}==0 & e(sample)
 16.                 scalar x = r(N)
 17.                 count if ${depvar}==0 & e(sample) 
 18.                 scalar y = r(N)
 19.                 scalar z2 = x/y
 20.                 noisily di "Correct Failure Prediction Rate: " z2
 21.                 noisily di "predicted =" x ", Actual = " y
 22. 
.                 noisily di " "
 23.                 
.                 count if `x'_yhat`y'> .5 & ${depvar}==0 & e(sample)
 24.                 scalar x = r(N)
 25.                 count if ${depvar}==1 & e(sample)
 26.                 scalar y = r(N)
 27.                 scalar z3 = x/y
 28.                 noisily di "Incorrect Success Prediction Rate: " z3
 29.                 noisily di "predicted =" x ", Actual = " y
 30. 
.                 noisily di " "
 31.                 
.                 count if `x'_yhat`y'<.5 & ${depvar}==1 & e(sample)
 32.                 scalar x = r(N)
 33.                 count if ${depvar}==0 & e(sample)
 34.                 scalar y = r(N)
 35.                 scalar z4 = x/y
 36.                 noisily di "Incorrect Failure Prediction Rate: " z4
 37.                 noisily di "predicted =" x ", Actual = " y
 38.                 matrix define prediction`x'`y' = (z1, z2, z3, z4)
 39. 
. di "==========================================================================="
 40. }
 41. }
(results regress_1 are active now)
============================================================
Model regress_1 regress unin age wage military race mz_wage mz_military [pweight=WGTRU13]
============================================================
  1,116
  1,393
Correct Success Prediction Rate: .8011486
predicted =1116, Actual = 1393
  
  715
  1,250
Correct Failure Prediction Rate: .572
predicted =715, Actual = 1250
 
  535
  1,393
Incorrect Success Prediction Rate: .38406317
predicted =535, Actual = 1393
 
  277
  1,250
Incorrect Failure Prediction Rate: .2216
predicted =277, Actual = 1250
===========================================================================
(results logit_1 are active now)
============================================================
Model logit_1 logit unin age wage military race mz_wage mz_military [pweight=WGTRU13]
============================================================
  1,068
  1,393
Correct Success Prediction Rate: .7666906
predicted =1068, Actual = 1393
  
  736
  1,246
Correct Failure Prediction Rate: .59069021
predicted =736, Actual = 1246
 
  510
  1,393
Incorrect Success Prediction Rate: .3661163
predicted =510, Actual = 1393
 
  325
  1,246
Incorrect Failure Prediction Rate: .26083467
predicted =325, Actual = 1246
===========================================================================
(results probit_1 are active now)
============================================================
Model probit_1 probit unin age wage military race mz_wage mz_military [pweight=WGTRU13]
============================================================
  1,085
  1,393
Correct Success Prediction Rate: .77889447
predicted =1085, Actual = 1393
  
  727
  1,246
Correct Failure Prediction Rate: .58346709
predicted =727, Actual = 1246
 
  519
  1,393
Incorrect Success Prediction Rate: .37257717
predicted =519, Actual = 1393
 
  308
  1,246
Incorrect Failure Prediction Rate: .24719101
predicted =308, Actual = 1246
===========================================================================
(results regress_2 are active now)
============================================================
Model regress_2 regress unin age wage military race employed mz_wage mz_employed mz_military [pweight=WGTRU13]
============================================================
  1,069
  1,358
Correct Success Prediction Rate: .78718704
predicted =1069, Actual = 1358
  
  721
  1,238
Correct Failure Prediction Rate: .58239095
predicted =721, Actual = 1238
 
  517
  1,358
Incorrect Success Prediction Rate: .38070692
predicted =517, Actual = 1358
 
  289
  1,238
Incorrect Failure Prediction Rate: .23344103
predicted =289, Actual = 1238
===========================================================================
(results logit_2 are active now)
============================================================
Model logit_2 logit unin age wage military race employed mz_wage mz_employed mz_military [pweight=WGTRU13]
============================================================
  1,025
  1,358
Correct Success Prediction Rate: .75478645
predicted =1025, Actual = 1358
  
  735
  1,234
Correct Failure Prediction Rate: .59562399
predicted =735, Actual = 1234
 
  499
  1,358
Incorrect Success Prediction Rate: .36745214
predicted =499, Actual = 1358
 
  333
  1,234
Incorrect Failure Prediction Rate: .26985413
predicted =333, Actual = 1234
===========================================================================
(results probit_2 are active now)
============================================================
Model probit_2 probit unin age wage military race employed mz_wage mz_employed mz_military [pweight=WGTRU13]
============================================================
  1,060
  1,358
Correct Success Prediction Rate: .78055965
predicted =1060, Actual = 1358
  
  723
  1,234
Correct Failure Prediction Rate: .58589951
predicted =723, Actual = 1234
 
  511
  1,358
Incorrect Success Prediction Rate: .37628866
predicted =511, Actual = 1358
 
  298
  1,234
Incorrect Failure Prediction Rate: .24149109
predicted =298, Actual = 1234
===========================================================================
(results regress_3 are active now)
============================================================
Model regress_3 regress unin age military race employed mz_employed mz_military [pweight=WGTRU13]
============================================================
  2,542
  2,906
Correct Success Prediction Rate: .87474191
predicted =2542, Actual = 2906
  
  333
  1,987
Correct Failure Prediction Rate: .16758933
predicted =333, Actual = 1987
 
  1,654
  2,906
Incorrect Success Prediction Rate: .56916724
predicted =1654, Actual = 2906
 
  364
  1,987
Incorrect Failure Prediction Rate: .18319074
predicted =364, Actual = 1987
===========================================================================
(results logit_3 are active now)
============================================================
Model logit_3 logit unin age military race employed mz_employed mz_military [pweight=WGTRU13]
============================================================
  2,535
  2,906
Correct Success Prediction Rate: .8723331
predicted =2535, Actual = 2906
  
  334
  1,983
Correct Failure Prediction Rate: .16843167
predicted =334, Actual = 1983
 
  1,649
  2,906
Incorrect Success Prediction Rate: .56744666
predicted =1649, Actual = 2906
 
  371
  1,983
Incorrect Failure Prediction Rate: .18709027
predicted =371, Actual = 1983
===========================================================================
(results probit_3 are active now)
============================================================
Model probit_3 probit unin age military race employed mz_employed mz_military [pweight=WGTRU13]
============================================================
  2,535
  2,906
Correct Success Prediction Rate: .8723331
predicted =2535, Actual = 2906
  
  334
  1,983
Correct Failure Prediction Rate: .16843167
predicted =334, Actual = 1983
 
  1,649
  2,906
Incorrect Success Prediction Rate: .56744666
predicted =1649, Actual = 2906
 
  371
  1,983
Incorrect Failure Prediction Rate: .18709027
predicted =371, Actual = 1983
===========================================================================

. 
. 
. 
. 
. forval y = 1/3 {
  2.         matrix accuracy`y' = (predictionregress`y' \ predictionlogit`y' \ predictionprobit`y')
  3.         matrix colnames accuracy`y' = correct_success correct_failure   inaccurate_success inaccurate_failure
  4.         matrix rownames accuracy`x'`y' = REGRESS LOGIT PROBIT
  5.         putexcel set "prediction2.csv", sheet(wgt`y') modify
  6.         putexcel A1 = matrix(accuracy`x'`y'), names nformat(number_d2)
  7. 
. }
file prediction2.csv saved
file prediction2.csv saved
file prediction2.csv saved

. 
. 
. ********************************************************************************
. ********************************************************************************
. *
. * Clustered Only
. *
. ********************************************************************************
. ********************************************************************************
. 
. cap drop *_uhat* *_yhat*

. 
. global option = ", vce(cluster DUID)"

. 
. local list = "regress logit probit"

. 
. 
. foreach x in `list' {
  2. 
. `x' ${depvar} ${model1} ${option}
  3. estimates store `x'_1
  4. predict `x'_uhat1, stdp
  5. predict `x'_yhat1 
  6. 
. `x' ${depvar} ${model2} ${option}
  7. estimates store `x'_2
  8. predict `x'_uhat2, stdp
  9. predict `x'_yhat2 
 10. 
. `x' ${depvar} ${model3} ${option}
 11. estimates store `x'_3
 12. predict `x'_uhat3, stdp
 13. predict `x'_yhat3 
 14. di "==========================================================================="
 15. }
note: mz_wage omitted because of collinearity
note: mz_military omitted because of collinearity

Linear regression                               Number of obs     =      2,694
                                                F(4, 838)         =      46.23
                                                Prob > F          =     0.0000
                                                R-squared         =     0.1539
                                                Root MSE          =     .45955

                                 (Std. Err. adjusted for 839 clusters in DUID)
------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   -.000097    .001766    -0.05   0.956    -.0035634    .0033694
        wage |  -.0145202   .0012852   -11.30   0.000    -.0170428   -.0119976
    military |   -.321043   .1225963    -2.62   0.009    -.5616749    -.080411
        race |  -.0654965   .0216359    -3.03   0.003    -.1079635   -.0230295
     mz_wage |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |    .922169   .0723326    12.75   0.000     .7801945    1.064143
------------------------------------------------------------------------------
(5,198 missing values generated)
(option xb assumed; fitted values)
(5,198 missing values generated)
note: employed omitted because of collinearity
note: mz_wage omitted because of collinearity
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity

Linear regression                               Number of obs     =      2,647
                                                F(4, 824)         =      46.04
                                                Prob > F          =     0.0000
                                                R-squared         =     0.1564
                                                Root MSE          =     .45907

                                 (Std. Err. adjusted for 825 clusters in DUID)
------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0005727   .0017949    -0.32   0.750    -.0040958    .0029503
        wage |  -.0143226   .0012868   -11.13   0.000    -.0168483   -.0117969
    military |  -.3154579   .1244239    -2.54   0.011    -.5596831   -.0712328
        race |  -.0689634   .0219081    -3.15   0.002    -.1119656   -.0259612
    employed |          0  (omitted)
     mz_wage |          0  (omitted)
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   .9405605   .0734062    12.81   0.000     .7964753    1.084646
------------------------------------------------------------------------------
(5,245 missing values generated)
(option xb assumed; fitted values)
(5,245 missing values generated)
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity

Linear regression                               Number of obs     =      4,968
                                                F(4, 1465)        =      41.02
                                                Prob > F          =     0.0000
                                                R-squared         =     0.0297
                                                Root MSE          =     .48408

                               (Std. Err. adjusted for 1,466 clusters in DUID)
------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0021925   .0012219    -1.79   0.073    -.0045893    .0002043
    military |  -.4998219   .0554541    -9.01   0.000    -.6085998    -.391044
        race |  -.0677466   .0156684    -4.32   0.000    -.0984814   -.0370118
    employed |  -.0787437   .0327425    -2.40   0.016    -.1429709   -.0145165
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |    .869506   .0580235    14.99   0.000     .7556881     .983324
------------------------------------------------------------------------------
(2,924 missing values generated)
(option xb assumed; fitted values)
(2,924 missing values generated)
===========================================================================

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_wage omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood = -1859.6849  
Iteration 1:   log pseudolikelihood = -1608.4448  
Iteration 2:   log pseudolikelihood = -1601.0981  
Iteration 3:   log pseudolikelihood = -1601.0747  
Iteration 4:   log pseudolikelihood = -1601.0747  

Logistic regression                             Number of obs     =      2,690
                                                Wald chi2(3)      =      73.35
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -1601.0747               Pseudo R2         =     0.1391

                                 (Std. Err. adjusted for 837 clusters in DUID)
------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0024224   .0084108     0.29   0.773    -.0140624    .0189072
        wage |  -.0986166   .0126511    -7.80   0.000    -.1234123   -.0738209
    military |          0  (omitted)
        race |  -.3115613   .1001371    -3.11   0.002    -.5078264   -.1152962
     mz_wage |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   2.296372   .3714429     6.18   0.000     1.568357    3.024387
------------------------------------------------------------------------------
(5202 missing values generated)
(option pr assumed; Pr(unin))
(5,202 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: employed omitted because of collinearity
note: mz_wage omitted because of collinearity
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood = -1828.3312  
Iteration 1:   log pseudolikelihood =  -1577.716  
Iteration 2:   log pseudolikelihood = -1570.0431  
Iteration 3:   log pseudolikelihood = -1570.0164  
Iteration 4:   log pseudolikelihood = -1570.0164  

Logistic regression                             Number of obs     =      2,643
                                                Wald chi2(3)      =      73.22
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -1570.0164               Pseudo R2         =     0.1413

                                 (Std. Err. adjusted for 823 clusters in DUID)
------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0000467   .0085411     0.01   0.996    -.0166935     .016787
        wage |  -.0978493   .0127005    -7.70   0.000    -.1227419   -.0729567
    military |          0  (omitted)
        race |  -.3266354   .1017123    -3.21   0.001    -.5259879    -.127283
    employed |          0  (omitted)
     mz_wage |          0  (omitted)
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   2.390424   .3804627     6.28   0.000     1.644731    3.136117
------------------------------------------------------------------------------
(5249 missing values generated)
(option pr assumed; Pr(unin))
(5,249 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood = -3352.7688  
Iteration 1:   log pseudolikelihood =  -3281.336  
Iteration 2:   log pseudolikelihood = -3281.2452  
Iteration 3:   log pseudolikelihood = -3281.2452  

Logistic regression                             Number of obs     =      4,964
                                                Wald chi2(3)      =      26.17
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -3281.2452               Pseudo R2         =     0.0213

                               (Std. Err. adjusted for 1,464 clusters in DUID)
------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0093261   .0052109    -1.79   0.073    -.0195394    .0008871
    military |          0  (omitted)
        race |  -.2839306   .0668673    -4.25   0.000    -.4149881   -.1528731
    employed |  -.3413385   .1446372    -2.36   0.018    -.6248222   -.0578549
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.558425   .2623777     5.94   0.000     1.044174    2.072676
------------------------------------------------------------------------------
(2928 missing values generated)
(option pr assumed; Pr(unin))
(2,928 missing values generated)
===========================================================================

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_wage omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood = -1859.6849  
Iteration 1:   log pseudolikelihood = -1609.2554  
Iteration 2:   log pseudolikelihood = -1603.3836  
Iteration 3:   log pseudolikelihood = -1603.3659  
Iteration 4:   log pseudolikelihood = -1603.3659  

Probit regression                               Number of obs     =      2,690
                                                Wald chi2(3)      =      75.89
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -1603.3659               Pseudo R2         =     0.1378

                                 (Std. Err. adjusted for 837 clusters in DUID)
------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0009981   .0049956     0.20   0.842    -.0087931    .0107893
        wage |  -.0574276    .007356    -7.81   0.000    -.0718452     -.04301
    military |          0  (omitted)
        race |  -.1908096   .0605141    -3.15   0.002     -.309415   -.0722043
     mz_wage |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.384901    .219701     6.30   0.000     .9542953    1.815507
------------------------------------------------------------------------------
(5202 missing values generated)
(option pr assumed; Pr(unin))
(5,202 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: employed omitted because of collinearity
note: mz_wage omitted because of collinearity
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood = -1828.3312  
Iteration 1:   log pseudolikelihood = -1578.2724  
Iteration 2:   log pseudolikelihood = -1572.2207  
Iteration 3:   log pseudolikelihood = -1572.2023  
Iteration 4:   log pseudolikelihood = -1572.2023  

Probit regression                               Number of obs     =      2,643
                                                Wald chi2(3)      =      76.30
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -1572.2023               Pseudo R2         =     0.1401

                                 (Std. Err. adjusted for 823 clusters in DUID)
------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0003988    .005071    -0.08   0.937    -.0103378    .0095401
        wage |  -.0569619   .0073702    -7.73   0.000    -.0714073   -.0425165
    military |          0  (omitted)
        race |   -.200355   .0613947    -3.26   0.001    -.3206864   -.0800236
    employed |          0  (omitted)
     mz_wage |          0  (omitted)
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.441171   .2244537     6.42   0.000      1.00125    1.881092
------------------------------------------------------------------------------
(5249 missing values generated)
(option pr assumed; Pr(unin))
(5,249 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood = -3352.7688  
Iteration 1:   log pseudolikelihood = -3280.8215  
Iteration 2:   log pseudolikelihood = -3280.7921  
Iteration 3:   log pseudolikelihood = -3280.7921  

Probit regression                               Number of obs     =      4,964
                                                Wald chi2(3)      =      27.06
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -3280.7921               Pseudo R2         =     0.0215

                               (Std. Err. adjusted for 1,464 clusters in DUID)
------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0056734   .0031897    -1.78   0.075    -.0119252    .0005784
    military |          0  (omitted)
        race |  -.1780165   .0414046    -4.30   0.000     -.259168    -.096865
    employed |  -.2093863   .0886599    -2.36   0.018    -.3831565   -.0356161
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   .9664032   .1592368     6.07   0.000     .6543048    1.278502
------------------------------------------------------------------------------
(2928 missing values generated)
(option pr assumed; Pr(unin))
(2,928 missing values generated)
===========================================================================

. 
. local list = "regress logit probit"

. 
. forval x = 1/3 {
  2. 
.         stderr regress_uhat`x' logit_uhat`x' probit_uhat`x' 
  3.         matrix define stderr`x' = (regress_uhat`x', logit_uhat`x' ,probit_uhat`x' )
  4. 
. }
stderr of regress_uhat1 = 0
stderr of logit_uhat1 = 0
stderr of probit_uhat1 = 0
stderr of regress_uhat2 = 0
stderr of logit_uhat2 = 0
stderr of probit_uhat2 = 0
stderr of regress_uhat3 = 0
stderr of logit_uhat3 = 0
stderr of probit_uhat3 = 0

. 
. matrix stderr = stderr1\stderr2\stderr3

. matrix rownames stderr = stderr1 stderr2 stderr

. matrix colnames stderr =  REGRESS LOGIT PROBIT

. 
. putexcel set "output2.csv", sheet(CLUSTERED) modify

. putexcel A1 = matrix(stderr), names nformat(number_d2)
file output2.csv saved

. 
. capture {

Probit model for unin

              -------- True --------
Classified |         D            ~D  |      Total
-----------+--------------------------+-----------
     +     |      2582          1705  |       4287
     -     |       366           311  |        677
-----------+--------------------------+-----------
   Total   |      2948          2016  |       4964

Classified + if predicted Pr(D) >= .5
True D defined as unin != 0
--------------------------------------------------
Sensitivity                     Pr( +| D)   87.58%
Specificity                     Pr( -|~D)   15.43%
Positive predictive value       Pr( D| +)   60.23%
Negative predictive value       Pr(~D| -)   45.94%
--------------------------------------------------
False + rate for true ~D        Pr( +|~D)   84.57%
False - rate for true D         Pr( -| D)   12.42%
False + rate for classified +   Pr(~D| +)   39.77%
False - rate for classified -   Pr( D| -)   54.06%
--------------------------------------------------
Correctly classified                        58.28%
--------------------------------------------------

Probit model for unin, goodness-of-fit test

       number of observations =      4964
 number of covariate patterns =       348
            Pearson chi2(344) =      1526.64
                  Prob > chi2 =         0.0000

Probit model for unin, goodness-of-fit test

  (Table collapsed on quantiles of estimated probabilities)

       number of observations =      4964
             number of groups =        10
      Hosmer-Lemeshow chi2(8) =       162.06
                  Prob > chi2 =         0.0000

Probit model for unin, goodness-of-fit test

  (Table collapsed on quantiles of estimated probabilities)
  +--------------------------------------------------------+
  | Group |   Prob | Obs_1 | Exp_1 | Obs_0 | Exp_0 | Total |
  |-------+--------+-------+-------+-------+-------+-------|
  |     1 | 0.4781 |   263 | 219.1 |   245 | 288.9 |   508 |
  |     2 | 0.5309 |   277 | 264.6 |   240 | 252.4 |   517 |
  |     3 | 0.5524 |   259 | 255.2 |   212 | 215.8 |   471 |
  |     4 | 0.5814 |   193 | 278.1 |   297 | 211.9 |   490 |
  |     5 | 0.6044 |   234 | 304.9 |   280 | 209.1 |   514 |
  |-------+--------+-------+-------+-------+-------+-------|
  |     6 | 0.6226 |   270 | 295.9 |   212 | 186.1 |   482 |
  |     7 | 0.6430 |   357 | 314.9 |   140 | 182.1 |   497 |
  |     8 | 0.6628 |   366 | 328.0 |   136 | 174.0 |   502 |
  |     9 | 0.6924 |   371 | 337.6 |   128 | 161.4 |   499 |
  |    10 | 0.7573 |   358 | 351.6 |   126 | 132.4 |   484 |
  +--------------------------------------------------------+

       number of observations =      4964
             number of groups =        10
      Hosmer-Lemeshow chi2(8) =       162.06
                  Prob > chi2 =         0.0000

. 
. foreach x in `list' {
  2.         estimates table `x'_1 `x'_2 `x'_3, ///
>           stats(N ll r2_p mrse) b(%7.3f) stfmt(%8.2f)
  3.           
.         sum `x'_yhat1 `x'_yhat2 `x'_yhat3 ${depvar}
  4. 
. }

--------------------------------------------------
    Variable | regress_1   regress_2   regress_3  
-------------+------------------------------------
         age |    -0.000      -0.001      -0.002  
        wage |    -0.015      -0.014              
    military |    -0.321      -0.315      -0.500  
        race |    -0.065      -0.069      -0.068  
     mz_wage | (omitted)   (omitted)              
 mz_military | (omitted)   (omitted)   (omitted)  
    employed |             (omitted)      -0.079  
 mz_employed |             (omitted)   (omitted)  
       _cons |     0.922       0.941       0.870  
-------------+------------------------------------
           N |      2694        2647        4968  
          ll |  -1725.51    -1692.62    -3442.51  
        r2_p |                                    
        mrse |                                    
--------------------------------------------------

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
regress_yh~1 |      2,694    .5293244    .1958584  -.5876917   .8280627
regress_yh~2 |      2,647    .5255006    .1975194  -.5919468    .830496
regress_yh~3 |      4,968    .5933977    .0847209  -.0699391   .7666792
        unin |      7,892          .5    .5000317          0          1

--------------------------------------------------
    Variable |  logit_1     logit_2     logit_3   
-------------+------------------------------------
         age |     0.002       0.000      -0.009  
        wage |    -0.099      -0.098              
    military | (omitted)   (omitted)   (omitted)  
        race |    -0.312      -0.327      -0.284  
     mz_wage | (omitted)   (omitted)              
 mz_military | (omitted)   (omitted)   (omitted)  
    employed |             (omitted)      -0.341  
 mz_employed |             (omitted)   (omitted)  
       _cons |     2.296       2.390       1.558  
-------------+------------------------------------
           N |      2690        2643        4964  
          ll |  -1601.07    -1570.02    -3281.25  
        r2_p |      0.14        0.14        0.02  
        mrse |                                    
--------------------------------------------------

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
 logit_yhat1 |      2,690    .5301115    .2073602   .0007035   .8672084
 logit_yhat2 |      2,643    .5262959    .2090418   .0006835    .868744
 logit_yhat3 |      4,964    .5938759    .0831398   .3222429    .754966
        unin |      7,892          .5    .5000317          0          1

--------------------------------------------------
    Variable | probit_1    probit_2    probit_3   
-------------+------------------------------------
         age |     0.001      -0.000      -0.006  
        wage |    -0.057      -0.057              
    military | (omitted)   (omitted)   (omitted)  
        race |    -0.191      -0.200      -0.178  
     mz_wage | (omitted)   (omitted)              
 mz_military | (omitted)   (omitted)   (omitted)  
    employed |             (omitted)      -0.209  
 mz_employed |             (omitted)   (omitted)  
       _cons |     1.385       1.441       0.966  
-------------+------------------------------------
           N |      2690        2643        4964  
          ll |  -1603.37    -1572.20    -3280.79  
        r2_p |      0.14        0.14        0.02  
        mrse |                                    
--------------------------------------------------

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
probit_yhat1 |      2,690     .531175    .2039881   .0000112   .8682685
probit_yhat2 |      2,643    .5274384    .2057657   .0000104   .8703582
probit_yhat3 |      4,964    .5942951    .0834356   .3219967   .7572902
        unin |      7,892          .5    .5000317          0          1

. 
. local list = "regress logit probit"

. 
. forval y = 1/3 {
  2. foreach x in `list' {
  3.         
.                 estimates restore `x'_`y'
  4.                 
.                 noisily di "============================================================"
  5.                 noisily di "Model `x'_`y' " e(cmdline)
  6.                 noisily di "============================================================"
  7. 
.                 count if `x'_yhat`y' > .5 & ${depvar}==1 & e(sample)
  8.                 scalar x = r(N)
  9.                 count if ${depvar}==1 & e(sample)
 10.                 scalar y = r(N)
 11.                 scalar z1 = x/y
 12.                 noisily di "Correct Success Prediction Rate: " z1
 13.                 noisily di "predicted =" x ", Actual = " y
 14. 
.                 noisily di "  "
 15. 
.                 count if `x'_yhat`y'<.5 & ${depvar}==0 & e(sample)
 16.                 scalar x = r(N)
 17.                 count if ${depvar}==0 & e(sample) 
 18.                 scalar y = r(N)
 19.                 scalar z2 = x/y
 20.                 noisily di "Correct Failure Prediction Rate: " z2
 21.                 noisily di "predicted =" x ", Actual = " y
 22. 
.                 noisily di " "
 23.                 
.                 count if `x'_yhat`y'> .5 & ${depvar}==0 & e(sample)
 24.                 scalar x = r(N)
 25.                 count if ${depvar}==1 & e(sample)
 26.                 scalar y = r(N)
 27.                 scalar z3 = x/y
 28.                 noisily di "Incorrect Success Prediction Rate: " z3
 29.                 noisily di "predicted =" x ", Actual = " y
 30. 
.                 noisily di " "
 31.                 
.                 count if `x'_yhat`y'<.5 & ${depvar}==1 & e(sample)
 32.                 scalar x = r(N)
 33.                 count if ${depvar}==0 & e(sample)
 34.                 scalar y = r(N)
 35.                 scalar z4 = x/y
 36.                 noisily di "Incorrect Failure Prediction Rate: " z4
 37.                 noisily di "predicted =" x ", Actual = " y
 38.                 matrix define prediction`x'`y' = (z1, z2, z3, z4)
 39. 
. di "==========================================================================="
 40. }
 41. }
(results regress_1 are active now)
============================================================
Model regress_1 regress unin age wage military race mz_wage mz_military , vce(cluster DUID)
============================================================
  1,186
  1,426
Correct Success Prediction Rate: .83169705
predicted =1186, Actual = 1426
  
  613
  1,268
Correct Failure Prediction Rate: .48343849
predicted =613, Actual = 1268
 
  655
  1,426
Incorrect Success Prediction Rate: .45932679
predicted =655, Actual = 1426
 
  240
  1,268
Incorrect Failure Prediction Rate: .18927445
predicted =240, Actual = 1268
===========================================================================
(results logit_1 are active now)
============================================================
Model logit_1 logit unin age wage military race mz_wage mz_military , vce(cluster DUID)
============================================================
  1,147
  1,426
Correct Success Prediction Rate: .80434783
predicted =1147, Actual = 1426
  
  726
  1,264
Correct Failure Prediction Rate: .57436709
predicted =726, Actual = 1264
 
  538
  1,426
Incorrect Success Prediction Rate: .3772791
predicted =538, Actual = 1426
 
  279
  1,264
Incorrect Failure Prediction Rate: .22072785
predicted =279, Actual = 1264
===========================================================================
(results probit_1 are active now)
============================================================
Model probit_1 probit unin age wage military race mz_wage mz_military , vce(cluster DUID)
============================================================
  1,144
  1,426
Correct Success Prediction Rate: .80224404
predicted =1144, Actual = 1426
  
  716
  1,264
Correct Failure Prediction Rate: .5664557
predicted =716, Actual = 1264
 
  548
  1,426
Incorrect Success Prediction Rate: .38429173
predicted =548, Actual = 1426
 
  282
  1,264
Incorrect Failure Prediction Rate: .22310127
predicted =282, Actual = 1264
===========================================================================
(results regress_2 are active now)
============================================================
Model regress_2 regress unin age wage military race employed mz_wage mz_employed mz_military , vce(cluster DUID)
============================================================
  1,156
  1,391
Correct Success Prediction Rate: .83105679
predicted =1156, Actual = 1391
  
  643
  1,256
Correct Failure Prediction Rate: .51194268
predicted =643, Actual = 1256
 
  613
  1,391
Incorrect Success Prediction Rate: .44069015
predicted =613, Actual = 1391
 
  235
  1,256
Incorrect Failure Prediction Rate: .18710191
predicted =235, Actual = 1256
===========================================================================
(results logit_2 are active now)
============================================================
Model logit_2 logit unin age wage military race employed mz_wage mz_employed mz_military , vce(cluster DUID)
============================================================
  1,094
  1,391
Correct Success Prediction Rate: .78648454
predicted =1094, Actual = 1391
  
  727
  1,252
Correct Failure Prediction Rate: .58067093
predicted =727, Actual = 1252
 
  525
  1,391
Incorrect Success Prediction Rate: .37742631
predicted =525, Actual = 1391
 
  297
  1,252
Incorrect Failure Prediction Rate: .23722045
predicted =297, Actual = 1252
===========================================================================
(results probit_2 are active now)
============================================================
Model probit_2 probit unin age wage military race employed mz_wage mz_employed mz_military , vce(cluster DUID)
============================================================
  1,099
  1,391
Correct Success Prediction Rate: .79007908
predicted =1099, Actual = 1391
  
  721
  1,252
Correct Failure Prediction Rate: .57587859
predicted =721, Actual = 1252
 
  531
  1,391
Incorrect Success Prediction Rate: .38173976
predicted =531, Actual = 1391
 
  292
  1,252
Incorrect Failure Prediction Rate: .23322684
predicted =292, Actual = 1252
===========================================================================
(results regress_3 are active now)
============================================================
Model regress_3 regress unin age military race employed mz_employed mz_military , vce(cluster DUID)
============================================================
  2,582
  2,948
Correct Success Prediction Rate: .87584803
predicted =2582, Actual = 2948
  
  315
  2,020
Correct Failure Prediction Rate: .15594059
predicted =315, Actual = 2020
 
  1,705
  2,948
Incorrect Success Prediction Rate: .57835821
predicted =1705, Actual = 2948
 
  366
  2,020
Incorrect Failure Prediction Rate: .18118812
predicted =366, Actual = 2020
===========================================================================
(results logit_3 are active now)
============================================================
Model logit_3 logit unin age military race employed mz_employed mz_military , vce(cluster DUID)
============================================================
  2,583
  2,948
Correct Success Prediction Rate: .87618725
predicted =2583, Actual = 2948
  
  311
  2,016
Correct Failure Prediction Rate: .15426587
predicted =311, Actual = 2016
 
  1,705
  2,948
Incorrect Success Prediction Rate: .57835821
predicted =1705, Actual = 2948
 
  365
  2,016
Incorrect Failure Prediction Rate: .18105159
predicted =365, Actual = 2016
===========================================================================
(results probit_3 are active now)
============================================================
Model probit_3 probit unin age military race employed mz_employed mz_military , vce(cluster DUID)
============================================================
  2,582
  2,948
Correct Success Prediction Rate: .87584803
predicted =2582, Actual = 2948
  
  311
  2,016
Correct Failure Prediction Rate: .15426587
predicted =311, Actual = 2016
 
  1,705
  2,948
Incorrect Success Prediction Rate: .57835821
predicted =1705, Actual = 2948
 
  366
  2,016
Incorrect Failure Prediction Rate: .18154762
predicted =366, Actual = 2016
===========================================================================

. 
. 
. 
. forval y = 1/3 {
  2.         matrix accuracy`y' = (predictionregress`y' \ predictionlogit`y' \ predictionprobit`y')  
  3. matrix colnames accuracy`y' = correct_success correct_failure   inaccurate_success inaccurate_failure
  4.         matrix rownames accuracy`x'`y' = REGRESS LOGIT PROBIT
  5.         putexcel set "prediction.csv", sheet(clus`y') modify
  6.         putexcel A1 = matrix(accuracy`x'`y'), names nformat(number_d2)
  7. 
. }
file prediction.csv saved
file prediction.csv saved
file prediction.csv saved

. 
. ********************************************************************************
. ********************************************************************************
. *
. * NO OPTIONS
. *
. ********************************************************************************
. ********************************************************************************
. 
. cap drop *uhat* *_yhat*

. 
. global option = " "

. 
. local list = "regress logit probit"

. 
. 
. foreach x in `list' {
  2. 
. `x' ${depvar} ${model1} ${option}
  3. estimates store `x'_1
  4. predict `x'_uhat1, stdp
  5. predict `x'_yhat1 
  6. 
. `x' ${depvar} ${model2} ${option}
  7. estimates store `x'_2
  8. predict `x'_uhat2, stdp
  9. predict `x'_yhat2 
 10. 
. `x' ${depvar} ${model3} ${option}
 11. estimates store `x'_3
 12. predict `x'_uhat3, stdp
 13. predict `x'_yhat3 
 14. di "==========================================================================="
 15. }
note: mz_wage omitted because of collinearity
note: mz_military omitted because of collinearity

      Source |       SS           df       MS      Number of obs   =     2,694
-------------+----------------------------------   F(4, 2689)      =    122.29
       Model |  103.304859         4  25.8262148   Prob > F        =    0.0000
    Residual |  567.878511     2,689  .211185761   R-squared       =    0.1539
-------------+----------------------------------   Adj R-squared   =    0.1527
       Total |   671.18337     2,693  .249232592   Root MSE        =    .45955

------------------------------------------------------------------------------
        unin |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   -.000097   .0007851    -0.12   0.902    -.0016365    .0014426
        wage |  -.0145202   .0007412   -19.59   0.000    -.0159736   -.0130668
    military |   -.321043   .2302217    -1.39   0.163    -.7724724    .1303865
        race |  -.0654965    .009109    -7.19   0.000    -.0833578   -.0476352
     mz_wage |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |    .922169   .0336699    27.39   0.000     .8561474    .9881905
------------------------------------------------------------------------------
(5,198 missing values generated)
(option xb assumed; fitted values)
(5,198 missing values generated)
note: employed omitted because of collinearity
note: mz_wage omitted because of collinearity
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity

      Source |       SS           df       MS      Number of obs   =     2,647
-------------+----------------------------------   F(4, 2642)      =    122.46
       Model |  103.230763         4  25.8076908   Prob > F        =    0.0000
    Residual |  556.797948     2,642  .210748656   R-squared       =    0.1564
-------------+----------------------------------   Adj R-squared   =    0.1551
       Total |  660.028712     2,646  .249443958   Root MSE        =    .45907

------------------------------------------------------------------------------
        unin |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0005727   .0007956    -0.72   0.472    -.0021329    .0009874
        wage |  -.0143226   .0007423   -19.30   0.000     -.015778   -.0128671
    military |  -.3154579   .2299881    -1.37   0.170     -.766433    .1355171
        race |  -.0689634   .0091811    -7.51   0.000    -.0869663   -.0509605
    employed |          0  (omitted)
     mz_wage |          0  (omitted)
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   .9405605   .0341377    27.55   0.000     .8736213      1.0075
------------------------------------------------------------------------------
(5,245 missing values generated)
(option xb assumed; fitted values)
(5,245 missing values generated)
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity

      Source |       SS           df       MS      Number of obs   =     4,968
-------------+----------------------------------   F(4, 4963)      =     38.03
       Model |  35.6512703         4  8.91281757   Prob > F        =    0.0000
    Residual |  1163.01218     4,963  .234336525   R-squared       =    0.0297
-------------+----------------------------------   Adj R-squared   =    0.0290
       Total |  1198.66345     4,967  .241325437   Root MSE        =    .48408

------------------------------------------------------------------------------
        unin |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0021925   .0005629    -3.90   0.000     -.003296    -.001089
    military |  -.4998219   .2422719    -2.06   0.039     -.974782   -.0248619
        race |  -.0677466   .0066832   -10.14   0.000    -.0808487   -.0546445
    employed |  -.0787437   .0153333    -5.14   0.000    -.1088037   -.0486837
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |    .869506   .0269455    32.27   0.000     .8166809    .9223311
------------------------------------------------------------------------------
(2,924 missing values generated)
(option xb assumed; fitted values)
(2,924 missing values generated)
===========================================================================

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_wage omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log likelihood = -1859.6849  
Iteration 1:   log likelihood = -1608.4448  
Iteration 2:   log likelihood = -1601.0981  
Iteration 3:   log likelihood = -1601.0747  
Iteration 4:   log likelihood = -1601.0747  

Logistic regression                             Number of obs     =      2,690
                                                LR chi2(3)        =     517.22
                                                Prob > chi2       =     0.0000
Log likelihood = -1601.0747                     Pseudo R2         =     0.1391

------------------------------------------------------------------------------
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0024224   .0037257     0.65   0.516    -.0048798    .0097246
        wage |  -.0986166   .0060301   -16.35   0.000    -.1104353   -.0867979
    military |          0  (omitted)
        race |  -.3115613   .0428633    -7.27   0.000    -.3955719   -.2275508
     mz_wage |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   2.296372   .1732699    13.25   0.000     1.956769    2.635975
------------------------------------------------------------------------------
(5202 missing values generated)
(option pr assumed; Pr(unin))
(5,202 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: employed omitted because of collinearity
note: mz_wage omitted because of collinearity
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log likelihood = -1828.3312  
Iteration 1:   log likelihood =  -1577.716  
Iteration 2:   log likelihood = -1570.0431  
Iteration 3:   log likelihood = -1570.0164  
Iteration 4:   log likelihood = -1570.0164  

Logistic regression                             Number of obs     =      2,643
                                                LR chi2(3)        =     516.63
                                                Prob > chi2       =     0.0000
Log likelihood = -1570.0164                     Pseudo R2         =     0.1413

------------------------------------------------------------------------------
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0000467   .0037772     0.01   0.990    -.0073565      .00745
        wage |  -.0978493   .0060536   -16.16   0.000    -.1097142   -.0859844
    military |          0  (omitted)
        race |  -.3266354   .0433479    -7.54   0.000    -.4115958   -.2416751
    employed |          0  (omitted)
     mz_wage |          0  (omitted)
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   2.390424   .1766869    13.53   0.000     2.044124    2.736724
------------------------------------------------------------------------------
(5249 missing values generated)
(option pr assumed; Pr(unin))
(5,249 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log likelihood = -3352.7688  
Iteration 1:   log likelihood =  -3281.336  
Iteration 2:   log likelihood = -3281.2452  
Iteration 3:   log likelihood = -3281.2452  

Logistic regression                             Number of obs     =      4,964
                                                LR chi2(3)        =     143.05
                                                Prob > chi2       =     0.0000
Log likelihood = -3281.2452                     Pseudo R2         =     0.0213

------------------------------------------------------------------------------
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0093261   .0024007    -3.88   0.000    -.0140314   -.0046209
    military |          0  (omitted)
        race |  -.2839306   .0285687    -9.94   0.000    -.3399242    -.227937
    employed |  -.3413385   .0665684    -5.13   0.000    -.4718102   -.2108669
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.558425   .1183865    13.16   0.000     1.326392    1.790458
------------------------------------------------------------------------------
(2928 missing values generated)
(option pr assumed; Pr(unin))
(2,928 missing values generated)
===========================================================================

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_wage omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log likelihood = -1859.6849  
Iteration 1:   log likelihood = -1609.2554  
Iteration 2:   log likelihood = -1603.3836  
Iteration 3:   log likelihood = -1603.3659  
Iteration 4:   log likelihood = -1603.3659  

Probit regression                               Number of obs     =      2,690
                                                LR chi2(3)        =     512.64
                                                Prob > chi2       =     0.0000
Log likelihood = -1603.3659                     Pseudo R2         =     0.1378

------------------------------------------------------------------------------
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0009981   .0022362     0.45   0.655    -.0033849     .005381
        wage |  -.0574276   .0033148   -17.32   0.000    -.0639245   -.0509308
    military |          0  (omitted)
        race |  -.1908096   .0261265    -7.30   0.000    -.2420166   -.1396027
     mz_wage |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.384901   .1029151    13.46   0.000     1.183192    1.586611
------------------------------------------------------------------------------
(5202 missing values generated)
(option pr assumed; Pr(unin))
(5,202 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: employed omitted because of collinearity
note: mz_wage omitted because of collinearity
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log likelihood = -1828.3312  
Iteration 1:   log likelihood = -1578.2724  
Iteration 2:   log likelihood = -1572.2207  
Iteration 3:   log likelihood = -1572.2023  
Iteration 4:   log likelihood = -1572.2023  

Probit regression                               Number of obs     =      2,643
                                                LR chi2(3)        =     512.26
                                                Prob > chi2       =     0.0000
Log likelihood = -1572.2023                     Pseudo R2         =     0.1401

------------------------------------------------------------------------------
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0003988   .0022677    -0.18   0.860    -.0048435    .0040459
        wage |  -.0569619   .0033272   -17.12   0.000    -.0634831   -.0504408
    military |          0  (omitted)
        race |   -.200355   .0263988    -7.59   0.000    -.2520957   -.1486143
    employed |          0  (omitted)
     mz_wage |          0  (omitted)
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.441171    .104762    13.76   0.000     1.235842    1.646501
------------------------------------------------------------------------------
(5249 missing values generated)
(option pr assumed; Pr(unin))
(5,249 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log likelihood = -3352.7688  
Iteration 1:   log likelihood = -3280.8215  
Iteration 2:   log likelihood = -3280.7921  
Iteration 3:   log likelihood = -3280.7921  

Probit regression                               Number of obs     =      4,964
                                                LR chi2(3)        =     143.95
                                                Prob > chi2       =     0.0000
Log likelihood = -3280.7921                     Pseudo R2         =     0.0215

------------------------------------------------------------------------------
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0056734   .0014775    -3.84   0.000    -.0085692   -.0027776
    military |          0  (omitted)
        race |  -.1780165   .0176741   -10.07   0.000    -.2126571   -.1433759
    employed |  -.2093863   .0408539    -5.13   0.000    -.2894584   -.1293142
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   .9664032   .0720719    13.41   0.000     .8251448    1.107662
------------------------------------------------------------------------------
(2928 missing values generated)
(option pr assumed; Pr(unin))
(2,928 missing values generated)
===========================================================================

. 
. 
. local list = "regress logit probit"

. 
. forval x = 1/3 {
  2. 
.         stderr regress_uhat`x' logit_uhat`x' probit_uhat`x' 
  3.         matrix define stderr`x' = (regress_uhat`x', logit_uhat`x' ,probit_uhat`x' )
  4. 
. }
stderr of regress_uhat1 = 0
stderr of logit_uhat1 = 0
stderr of probit_uhat1 = 0
stderr of regress_uhat2 = 0
stderr of logit_uhat2 = 0
stderr of probit_uhat2 = 0
stderr of regress_uhat3 = 0
stderr of logit_uhat3 = 0
stderr of probit_uhat3 = 0

. 
. matrix stderr = stderr1\stderr2\stderr3

. matrix rownames stderr = stderr1 stderr2 stderr

. matrix colnames stderr =  REGRESS LOGIT PROBIT

. 
. putexcel set "output2.csv", sheet(NO OPTIONS) modify

. putexcel A1 = matrix(stderr), names nformat(number_d2)
file output2.csv saved

. 
. capture {

Probit model for unin

              -------- True --------
Classified |         D            ~D  |      Total
-----------+--------------------------+-----------
     +     |      2582          1705  |       4287
     -     |       366           311  |        677
-----------+--------------------------+-----------
   Total   |      2948          2016  |       4964

Classified + if predicted Pr(D) >= .5
True D defined as unin != 0
--------------------------------------------------
Sensitivity                     Pr( +| D)   87.58%
Specificity                     Pr( -|~D)   15.43%
Positive predictive value       Pr( D| +)   60.23%
Negative predictive value       Pr(~D| -)   45.94%
--------------------------------------------------
False + rate for true ~D        Pr( +|~D)   84.57%
False - rate for true D         Pr( -| D)   12.42%
False + rate for classified +   Pr(~D| +)   39.77%
False - rate for classified -   Pr( D| -)   54.06%
--------------------------------------------------
Correctly classified                        58.28%
--------------------------------------------------

Probit model for unin, goodness-of-fit test

       number of observations =      4964
 number of covariate patterns =       348
            Pearson chi2(344) =      1526.64
                  Prob > chi2 =         0.0000

Probit model for unin, goodness-of-fit test

  (Table collapsed on quantiles of estimated probabilities)

       number of observations =      4964
             number of groups =        10
      Hosmer-Lemeshow chi2(8) =       162.06
                  Prob > chi2 =         0.0000

Probit model for unin, goodness-of-fit test

  (Table collapsed on quantiles of estimated probabilities)
  +--------------------------------------------------------+
  | Group |   Prob | Obs_1 | Exp_1 | Obs_0 | Exp_0 | Total |
  |-------+--------+-------+-------+-------+-------+-------|
  |     1 | 0.4781 |   263 | 219.1 |   245 | 288.9 |   508 |
  |     2 | 0.5309 |   277 | 264.6 |   240 | 252.4 |   517 |
  |     3 | 0.5524 |   259 | 255.2 |   212 | 215.8 |   471 |
  |     4 | 0.5814 |   193 | 278.1 |   297 | 211.9 |   490 |
  |     5 | 0.6044 |   234 | 304.9 |   280 | 209.1 |   514 |
  |-------+--------+-------+-------+-------+-------+-------|
  |     6 | 0.6226 |   270 | 295.9 |   212 | 186.1 |   482 |
  |     7 | 0.6430 |   357 | 314.9 |   140 | 182.1 |   497 |
  |     8 | 0.6628 |   366 | 328.0 |   136 | 174.0 |   502 |
  |     9 | 0.6924 |   371 | 337.6 |   128 | 161.4 |   499 |
  |    10 | 0.7573 |   358 | 351.6 |   126 | 132.4 |   484 |
  +--------------------------------------------------------+

       number of observations =      4964
             number of groups =        10
      Hosmer-Lemeshow chi2(8) =       162.06
                  Prob > chi2 =         0.0000

. 
. foreach x in `list' {
  2. 
.         estimates table `x'_1 `x'_2 `x'_3, ///
>           stats(N ll r2_p mrse) b(%7.3f) stfmt(%8.2f)
  3.           
.         sum `x'_yhat1 `x'_yhat2 `x'_yhat3 ${depvar}
  4.         sum `x'_uhat1 `x'_uhat2 `x'_uhat3 
  5. }

--------------------------------------------------
    Variable | regress_1   regress_2   regress_3  
-------------+------------------------------------
         age |    -0.000      -0.001      -0.002  
        wage |    -0.015      -0.014              
    military |    -0.321      -0.315      -0.500  
        race |    -0.065      -0.069      -0.068  
     mz_wage | (omitted)   (omitted)              
 mz_military | (omitted)   (omitted)   (omitted)  
    employed |             (omitted)      -0.079  
 mz_employed |             (omitted)   (omitted)  
       _cons |     0.922       0.941       0.870  
-------------+------------------------------------
           N |      2694        2647        4968  
          ll |  -1725.51    -1692.62    -3442.51  
        r2_p |                                    
        mrse |                                    
--------------------------------------------------

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
regress_yh~1 |      2,694    .5293244    .1958584  -.5876917   .8280627
regress_yh~2 |      2,647    .5255006    .1975194  -.5919468    .830496
regress_yh~3 |      4,968    .5933977    .0847209  -.0699391   .7666792
        unin |      7,892          .5    .5000317          0          1

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
regress_uh~1 |      7,892    .0058254    .0099938          0   .2299983
regress_uh~2 |      7,892    .0057698    .0100121          0    .229763
regress_uh~3 |      7,892    .0084864    .0087439          0   .2421339

--------------------------------------------------
    Variable |  logit_1     logit_2     logit_3   
-------------+------------------------------------
         age |     0.002       0.000      -0.009  
        wage |    -0.099      -0.098              
    military | (omitted)   (omitted)   (omitted)  
        race |    -0.312      -0.327      -0.284  
     mz_wage | (omitted)   (omitted)              
 mz_military | (omitted)   (omitted)   (omitted)  
    employed |             (omitted)      -0.341  
 mz_employed |             (omitted)   (omitted)  
       _cons |     2.296       2.390       1.558  
-------------+------------------------------------
           N |      2690        2643        4964  
          ll |  -1601.07    -1570.02    -3281.25  
        r2_p |      0.14        0.14        0.02  
        mrse |                                    
--------------------------------------------------

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
 logit_yhat1 |      2,690    .5301115    .2073602   .0007035   .8672084
 logit_yhat2 |      2,643    .5262959    .2090418   .0006835    .868744
 logit_yhat3 |      4,964    .5938759    .0831398   .3222429    .754966
        unin |      7,892          .5    .5000317          0          1

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
 logit_uhat1 |      7,892    .0312619    .0520803          0   .4278236
 logit_uhat2 |      7,892    .0310636    .0523661          0    .430217
 logit_uhat3 |      7,892    .0358436    .0300008          0   .1120128

--------------------------------------------------
    Variable | probit_1    probit_2    probit_3   
-------------+------------------------------------
         age |     0.001      -0.000      -0.006  
        wage |    -0.057      -0.057              
    military | (omitted)   (omitted)   (omitted)  
        race |    -0.191      -0.200      -0.178  
     mz_wage | (omitted)   (omitted)              
 mz_military | (omitted)   (omitted)   (omitted)  
    employed |             (omitted)      -0.209  
 mz_employed |             (omitted)   (omitted)  
       _cons |     1.385       1.441       0.966  
-------------+------------------------------------
           N |      2690        2643        4964  
          ll |  -1603.37    -1572.20    -3280.79  
        r2_p |      0.14        0.14        0.02  
        mrse |                                    
--------------------------------------------------

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
probit_yhat1 |      2,690     .531175    .2039881   .0000112   .8682685
probit_yhat2 |      2,643    .5274384    .2057657   .0000104   .8703582
probit_yhat3 |      4,964    .5942951    .0834356   .3219967   .7572902
        unin |      7,892          .5    .5000317          0          1

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
probit_uhat1 |      7,892    .0183449    .0298494          0   .2346886
probit_uhat2 |      7,892    .0182159    .0299943          0   .2357888
probit_uhat3 |      7,892    .0221061    .0184697          0   .0693436

. 
. local list = "regress logit probit"

. 
. forval y = 1/3 {
  2. foreach x in `list' {
  3.         
.                 estimates restore `x'_`y'
  4.                 
.                 noisily di "============================================================"
  5.                 noisily di "Model `x'_`y' " e(cmdline)
  6.                 noisily di "============================================================"
  7. 
.                 count if `x'_yhat`y' > .5 & ${depvar}==1 & e(sample)
  8.                 scalar x = r(N)
  9.                 count if ${depvar}==1 & e(sample)
 10.                 scalar y = r(N)
 11.                 scalar z1 = x/y
 12.                 noisily di "Correct Success Prediction Rate: " z1
 13.                 noisily di "predicted =" x ", Actual = " y
 14. 
.                 noisily di "  "
 15. 
.                 count if `x'_yhat`y'<.5 & ${depvar}==0 & e(sample)
 16.                 scalar x = r(N)
 17.                 count if ${depvar}==0 & e(sample) 
 18.                 scalar y = r(N)
 19.                 scalar z2 = x/y
 20.                 noisily di "Correct Failure Prediction Rate: " z2
 21.                 noisily di "predicted =" x ", Actual = " y
 22. 
.                 noisily di " "
 23.                 
.                 count if `x'_yhat`y'> .5 & ${depvar}==0 & e(sample)
 24.                 scalar x = r(N)
 25.                 count if ${depvar}==1 & e(sample)
 26.                 scalar y = r(N)
 27.                 scalar z3 = x/y
 28.                 noisily di "Incorrect Success Prediction Rate: " z3
 29.                 noisily di "predicted =" x ", Actual = " y
 30. 
.                 noisily di " "
 31.                 
.                 count if `x'_yhat`y'<.5 & ${depvar}==1 & e(sample)
 32.                 scalar x = r(N)
 33.                 count if ${depvar}==0 & e(sample)
 34.                 scalar y = r(N)
 35.                 scalar z4 = x/y
 36.                 noisily di "Incorrect Failure Prediction Rate: " z4
 37.                 noisily di "predicted =" x ", Actual = " y
 38.                 matrix define prediction`x'`y' = (z1, z2, z3, z4)
 39. 
. di "==========================================================================="
 40. }
 41. }
(results regress_1 are active now)
============================================================
Model regress_1 regress unin age wage military race mz_wage mz_military  
============================================================
  1,186
  1,426
Correct Success Prediction Rate: .83169705
predicted =1186, Actual = 1426
  
  613
  1,268
Correct Failure Prediction Rate: .48343849
predicted =613, Actual = 1268
 
  655
  1,426
Incorrect Success Prediction Rate: .45932679
predicted =655, Actual = 1426
 
  240
  1,268
Incorrect Failure Prediction Rate: .18927445
predicted =240, Actual = 1268
===========================================================================
(results logit_1 are active now)
============================================================
Model logit_1 logit unin age wage military race mz_wage mz_military  
============================================================
  1,147
  1,426
Correct Success Prediction Rate: .80434783
predicted =1147, Actual = 1426
  
  726
  1,264
Correct Failure Prediction Rate: .57436709
predicted =726, Actual = 1264
 
  538
  1,426
Incorrect Success Prediction Rate: .3772791
predicted =538, Actual = 1426
 
  279
  1,264
Incorrect Failure Prediction Rate: .22072785
predicted =279, Actual = 1264
===========================================================================
(results probit_1 are active now)
============================================================
Model probit_1 probit unin age wage military race mz_wage mz_military  
============================================================
  1,144
  1,426
Correct Success Prediction Rate: .80224404
predicted =1144, Actual = 1426
  
  716
  1,264
Correct Failure Prediction Rate: .5664557
predicted =716, Actual = 1264
 
  548
  1,426
Incorrect Success Prediction Rate: .38429173
predicted =548, Actual = 1426
 
  282
  1,264
Incorrect Failure Prediction Rate: .22310127
predicted =282, Actual = 1264
===========================================================================
(results regress_2 are active now)
============================================================
Model regress_2 regress unin age wage military race employed mz_wage mz_employed mz_military  
============================================================
  1,156
  1,391
Correct Success Prediction Rate: .83105679
predicted =1156, Actual = 1391
  
  643
  1,256
Correct Failure Prediction Rate: .51194268
predicted =643, Actual = 1256
 
  613
  1,391
Incorrect Success Prediction Rate: .44069015
predicted =613, Actual = 1391
 
  235
  1,256
Incorrect Failure Prediction Rate: .18710191
predicted =235, Actual = 1256
===========================================================================
(results logit_2 are active now)
============================================================
Model logit_2 logit unin age wage military race employed mz_wage mz_employed mz_military  
============================================================
  1,094
  1,391
Correct Success Prediction Rate: .78648454
predicted =1094, Actual = 1391
  
  727
  1,252
Correct Failure Prediction Rate: .58067093
predicted =727, Actual = 1252
 
  525
  1,391
Incorrect Success Prediction Rate: .37742631
predicted =525, Actual = 1391
 
  297
  1,252
Incorrect Failure Prediction Rate: .23722045
predicted =297, Actual = 1252
===========================================================================
(results probit_2 are active now)
============================================================
Model probit_2 probit unin age wage military race employed mz_wage mz_employed mz_military  
============================================================
  1,099
  1,391
Correct Success Prediction Rate: .79007908
predicted =1099, Actual = 1391
  
  721
  1,252
Correct Failure Prediction Rate: .57587859
predicted =721, Actual = 1252
 
  531
  1,391
Incorrect Success Prediction Rate: .38173976
predicted =531, Actual = 1391
 
  292
  1,252
Incorrect Failure Prediction Rate: .23322684
predicted =292, Actual = 1252
===========================================================================
(results regress_3 are active now)
============================================================
Model regress_3 regress unin age military race employed mz_employed mz_military  
============================================================
  2,582
  2,948
Correct Success Prediction Rate: .87584803
predicted =2582, Actual = 2948
  
  315
  2,020
Correct Failure Prediction Rate: .15594059
predicted =315, Actual = 2020
 
  1,705
  2,948
Incorrect Success Prediction Rate: .57835821
predicted =1705, Actual = 2948
 
  366
  2,020
Incorrect Failure Prediction Rate: .18118812
predicted =366, Actual = 2020
===========================================================================
(results logit_3 are active now)
============================================================
Model logit_3 logit unin age military race employed mz_employed mz_military  
============================================================
  2,583
  2,948
Correct Success Prediction Rate: .87618725
predicted =2583, Actual = 2948
  
  311
  2,016
Correct Failure Prediction Rate: .15426587
predicted =311, Actual = 2016
 
  1,705
  2,948
Incorrect Success Prediction Rate: .57835821
predicted =1705, Actual = 2948
 
  365
  2,016
Incorrect Failure Prediction Rate: .18105159
predicted =365, Actual = 2016
===========================================================================
(results probit_3 are active now)
============================================================
Model probit_3 probit unin age military race employed mz_employed mz_military  
============================================================
  2,582
  2,948
Correct Success Prediction Rate: .87584803
predicted =2582, Actual = 2948
  
  311
  2,016
Correct Failure Prediction Rate: .15426587
predicted =311, Actual = 2016
 
  1,705
  2,948
Incorrect Success Prediction Rate: .57835821
predicted =1705, Actual = 2948
 
  366
  2,016
Incorrect Failure Prediction Rate: .18154762
predicted =366, Actual = 2016
===========================================================================

. 
. 
. 
. 
. forval y = 1/3 {
  2.         matrix accuracy`y' = (predictionregress`y' \ predictionlogit`y' \ predictionprobit`y')
  3.         matrix colnames accuracy`y' = correct_success correct_failure   inaccurate_success inaccurate_failure
  4.         matrix rownames accuracy`x'`y' = REGRESS LOGIT PROBIT
  5.         putexcel set "prediction2.csv", sheet(nooptions`y') modify
  6.         putexcel A1 = matrix(accuracy`x'`y'), names nformat(number_d2)
  7. 
. }
file prediction2.csv saved
file prediction2.csv saved
file prediction2.csv saved

. 
. 
. ********************************************************************************
. ********************************************************************************
. *
. * ROBUST ONLY 
. *
. ********************************************************************************
. ********************************************************************************
. cap drop *_uhat* *_yhat*

. 
. global option = ", robust "

. 
. local list = "regress logit probit"

. 
. 
. foreach x in `list' {
  2. 
. `x' ${depvar} ${model1} ${option}
  3. estimates store `x'_1
  4. predict `x'_uhat1, stdp
  5. predict `x'_yhat1 
  6. 
. `x' ${depvar} ${model2} ${option}
  7. estimates store `x'_2
  8. predict `x'_uhat2, stdp
  9. predict `x'_yhat2 
 10. 
. `x' ${depvar} ${model3} ${option}
 11. estimates store `x'_3
 12. predict `x'_uhat3, stdp
 13. predict `x'_yhat3 
 14. di "==========================================================================="
 15. 
. }
note: mz_wage omitted because of collinearity
note: mz_military omitted because of collinearity

Linear regression                               Number of obs     =      2,694
                                                F(4, 2689)        =     187.92
                                                Prob > F          =     0.0000
                                                R-squared         =     0.1539
                                                Root MSE          =     .45955

------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   -.000097   .0008273    -0.12   0.907    -.0017191    .0015251
        wage |  -.0145202   .0006219   -23.35   0.000    -.0157397   -.0133007
    military |   -.321043   .0851079    -3.77   0.000    -.4879266   -.1541593
        race |  -.0654965   .0093516    -7.00   0.000    -.0838334   -.0471595
     mz_wage |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |    .922169   .0338545    27.24   0.000     .8557855    .9885524
------------------------------------------------------------------------------
(5,198 missing values generated)
(option xb assumed; fitted values)
(5,198 missing values generated)
note: employed omitted because of collinearity
note: mz_wage omitted because of collinearity
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity

Linear regression                               Number of obs     =      2,647
                                                F(4, 2642)        =     188.35
                                                Prob > F          =     0.0000
                                                R-squared         =     0.1564
                                                Root MSE          =     .45907

------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0005727   .0008396    -0.68   0.495     -.002219    .0010736
        wage |  -.0143226   .0006217   -23.04   0.000    -.0155416   -.0131036
    military |  -.3154579   .0863835    -3.65   0.000    -.4848442   -.1460717
        race |  -.0689634   .0094303    -7.31   0.000    -.0874549   -.0504719
    employed |          0  (omitted)
     mz_wage |          0  (omitted)
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   .9405605   .0342478    27.46   0.000     .8734053    1.007716
------------------------------------------------------------------------------
(5,245 missing values generated)
(option xb assumed; fitted values)
(5,245 missing values generated)
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity

Linear regression                               Number of obs     =      4,968
                                                F(4, 4963)        =     108.58
                                                Prob > F          =     0.0000
                                                R-squared         =     0.0297
                                                Root MSE          =     .48408

------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0021925   .0005761    -3.81   0.000     -.003322    -.001063
    military |  -.4998219   .0366755   -13.63   0.000    -.5717221   -.4279218
        race |  -.0677466   .0066536   -10.18   0.000    -.0807907   -.0547026
    employed |  -.0787437   .0151089    -5.21   0.000    -.1083639   -.0491235
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |    .869506   .0266861    32.58   0.000     .8171895    .9218226
------------------------------------------------------------------------------
(2,924 missing values generated)
(option xb assumed; fitted values)
(2,924 missing values generated)
===========================================================================

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_wage omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood = -1859.6849  
Iteration 1:   log pseudolikelihood = -1608.4448  
Iteration 2:   log pseudolikelihood = -1601.0981  
Iteration 3:   log pseudolikelihood = -1601.0747  
Iteration 4:   log pseudolikelihood = -1601.0747  

Logistic regression                             Number of obs     =      2,690
                                                Wald chi2(3)      =     287.48
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -1601.0747               Pseudo R2         =     0.1391

------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0024224   .0039335     0.62   0.538    -.0052871    .0101319
        wage |  -.0986166   .0064728   -15.24   0.000    -.1113031   -.0859301
    military |          0  (omitted)
        race |  -.3115613   .0431254    -7.22   0.000    -.3960856    -.227037
     mz_wage |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   2.296372   .1764204    13.02   0.000     1.950595     2.64215
------------------------------------------------------------------------------
(5202 missing values generated)
(option pr assumed; Pr(unin))
(5,202 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: employed omitted because of collinearity
note: mz_wage omitted because of collinearity
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood = -1828.3312  
Iteration 1:   log pseudolikelihood =  -1577.716  
Iteration 2:   log pseudolikelihood = -1570.0431  
Iteration 3:   log pseudolikelihood = -1570.0164  
Iteration 4:   log pseudolikelihood = -1570.0164  

Logistic regression                             Number of obs     =      2,643
                                                Wald chi2(3)      =     288.83
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -1570.0164               Pseudo R2         =     0.1413

------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0000467   .0039887     0.01   0.991     -.007771    .0078644
        wage |  -.0978493   .0064986   -15.06   0.000    -.1105863   -.0851123
    military |          0  (omitted)
        race |  -.3266354   .0436299    -7.49   0.000    -.4121484   -.2411224
    employed |          0  (omitted)
     mz_wage |          0  (omitted)
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   2.390424   .1801265    13.27   0.000     2.037382    2.743465
------------------------------------------------------------------------------
(5249 missing values generated)
(option pr assumed; Pr(unin))
(5,249 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood = -3352.7688  
Iteration 1:   log pseudolikelihood =  -3281.336  
Iteration 2:   log pseudolikelihood = -3281.2452  
Iteration 3:   log pseudolikelihood = -3281.2452  

Logistic regression                             Number of obs     =      4,964
                                                Wald chi2(3)      =     136.01
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -3281.2452               Pseudo R2         =     0.0213

------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0093261   .0024568    -3.80   0.000    -.0141414   -.0045109
    military |          0  (omitted)
        race |  -.2839306   .0283981   -10.00   0.000    -.3395899   -.2282713
    employed |  -.3413385   .0667281    -5.12   0.000    -.4721231   -.2105539
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.558425   .1204424    12.94   0.000     1.322362    1.794488
------------------------------------------------------------------------------
(2928 missing values generated)
(option pr assumed; Pr(unin))
(2,928 missing values generated)
===========================================================================

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_wage omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood = -1859.6849  
Iteration 1:   log pseudolikelihood = -1609.2554  
Iteration 2:   log pseudolikelihood = -1603.3836  
Iteration 3:   log pseudolikelihood = -1603.3659  
Iteration 4:   log pseudolikelihood = -1603.3659  

Probit regression                               Number of obs     =      2,690
                                                Wald chi2(3)      =     286.53
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -1603.3659               Pseudo R2         =     0.1378

------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |   .0009981   .0023587     0.42   0.672     -.003625    .0056211
        wage |  -.0574276   .0038732   -14.83   0.000    -.0650189   -.0498363
    military |          0  (omitted)
        race |  -.1908096   .0261437    -7.30   0.000    -.2420503    -.139569
     mz_wage |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.384901   .1043106    13.28   0.000     1.180456    1.589347
------------------------------------------------------------------------------
(5202 missing values generated)
(option pr assumed; Pr(unin))
(5,202 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: employed omitted because of collinearity
note: mz_wage omitted because of collinearity
note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood = -1828.3312  
Iteration 1:   log pseudolikelihood = -1578.2724  
Iteration 2:   log pseudolikelihood = -1572.2207  
Iteration 3:   log pseudolikelihood = -1572.2023  
Iteration 4:   log pseudolikelihood = -1572.2023  

Probit regression                               Number of obs     =      2,643
                                                Wald chi2(3)      =     290.80
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -1572.2023               Pseudo R2         =     0.1401

------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0003988   .0023907    -0.17   0.868    -.0050845    .0042869
        wage |  -.0569619   .0038771   -14.69   0.000    -.0645609    -.049363
    military |          0  (omitted)
        race |   -.200355   .0264236    -7.58   0.000    -.2521444   -.1485656
    employed |          0  (omitted)
     mz_wage |          0  (omitted)
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   1.441171   .1062218    13.57   0.000      1.23298    1.649362
------------------------------------------------------------------------------
(5249 missing values generated)
(option pr assumed; Pr(unin))
(5,249 missing values generated)

note: military != 0 predicts failure perfectly
      military dropped and 4 obs not used

note: mz_employed omitted because of collinearity
note: mz_military omitted because of collinearity
Iteration 0:   log pseudolikelihood = -3352.7688  
Iteration 1:   log pseudolikelihood = -3280.8215  
Iteration 2:   log pseudolikelihood = -3280.7921  
Iteration 3:   log pseudolikelihood = -3280.7921  

Probit regression                               Number of obs     =      4,964
                                                Wald chi2(3)      =     140.63
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -3280.7921               Pseudo R2         =     0.0215

------------------------------------------------------------------------------
             |               Robust
        unin |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         age |  -.0056734   .0015042    -3.77   0.000    -.0086217   -.0027251
    military |          0  (omitted)
        race |  -.1780165   .0175869   -10.12   0.000    -.2124862   -.1435468
    employed |  -.2093863   .0408961    -5.12   0.000    -.2895412   -.1292314
 mz_employed |          0  (omitted)
 mz_military |          0  (omitted)
       _cons |   .9664032   .0730556    13.23   0.000     .8232168     1.10959
------------------------------------------------------------------------------
(2928 missing values generated)
(option pr assumed; Pr(unin))
(2,928 missing values generated)
===========================================================================

. 
. local list = "regress logit probit"

. 
. forval x = 1/3 {
  2. 
.         stderr regress_uhat`x' logit_uhat`x' probit_uhat`x' 
  3.         matrix define stderr`x' = (regress_uhat`x', logit_uhat`x' ,probit_uhat`x' )
  4. 
. }
stderr of regress_uhat1 = 0
stderr of logit_uhat1 = 0
stderr of probit_uhat1 = 0
stderr of regress_uhat2 = 0
stderr of logit_uhat2 = 0
stderr of probit_uhat2 = 0
stderr of regress_uhat3 = 0
stderr of logit_uhat3 = 0
stderr of probit_uhat3 = 0

. 
. matrix stderr = stderr1\stderr2\stderr3

. matrix rownames stderr = stderr1 stderr2 stderr

. matrix colnames stderr =  REGRESS LOGIT PROBIT

. 
. putexcel set "output2.csv", sheet(ROBUST) modify

. putexcel A1 = matrix(stderr), names nformat(number_d2)
file output2.csv saved

. 
. 
. capture {

Probit model for unin

              -------- True --------
Classified |         D            ~D  |      Total
-----------+--------------------------+-----------
     +     |      2582          1705  |       4287
     -     |       366           311  |        677
-----------+--------------------------+-----------
   Total   |      2948          2016  |       4964

Classified + if predicted Pr(D) >= .5
True D defined as unin != 0
--------------------------------------------------
Sensitivity                     Pr( +| D)   87.58%
Specificity                     Pr( -|~D)   15.43%
Positive predictive value       Pr( D| +)   60.23%
Negative predictive value       Pr(~D| -)   45.94%
--------------------------------------------------
False + rate for true ~D        Pr( +|~D)   84.57%
False - rate for true D         Pr( -| D)   12.42%
False + rate for classified +   Pr(~D| +)   39.77%
False - rate for classified -   Pr( D| -)   54.06%
--------------------------------------------------
Correctly classified                        58.28%
--------------------------------------------------

Probit model for unin, goodness-of-fit test

       number of observations =      4964
 number of covariate patterns =       348
            Pearson chi2(344) =      1526.64
                  Prob > chi2 =         0.0000

Probit model for unin, goodness-of-fit test

  (Table collapsed on quantiles of estimated probabilities)

       number of observations =      4964
             number of groups =        10
      Hosmer-Lemeshow chi2(8) =       162.06
                  Prob > chi2 =         0.0000

Probit model for unin, goodness-of-fit test

  (Table collapsed on quantiles of estimated probabilities)
  +--------------------------------------------------------+
  | Group |   Prob | Obs_1 | Exp_1 | Obs_0 | Exp_0 | Total |
  |-------+--------+-------+-------+-------+-------+-------|
  |     1 | 0.4781 |   263 | 219.1 |   245 | 288.9 |   508 |
  |     2 | 0.5309 |   277 | 264.6 |   240 | 252.4 |   517 |
  |     3 | 0.5524 |   259 | 255.2 |   212 | 215.8 |   471 |
  |     4 | 0.5814 |   193 | 278.1 |   297 | 211.9 |   490 |
  |     5 | 0.6044 |   234 | 304.9 |   280 | 209.1 |   514 |
  |-------+--------+-------+-------+-------+-------+-------|
  |     6 | 0.6226 |   270 | 295.9 |   212 | 186.1 |   482 |
  |     7 | 0.6430 |   357 | 314.9 |   140 | 182.1 |   497 |
  |     8 | 0.6628 |   366 | 328.0 |   136 | 174.0 |   502 |
  |     9 | 0.6924 |   371 | 337.6 |   128 | 161.4 |   499 |
  |    10 | 0.7573 |   358 | 351.6 |   126 | 132.4 |   484 |
  +--------------------------------------------------------+

       number of observations =      4964
             number of groups =        10
      Hosmer-Lemeshow chi2(8) =       162.06
                  Prob > chi2 =         0.0000

. 
. foreach x in `list' {
  2. 
. estimates table `x'_1 `x'_2 `x'_3, ///
>   stats(N ll r2_p mrse) b(%7.3f) stfmt(%8.2f)
  3.   
. sum `x'_yhat1 `x'_yhat2 `x'_yhat3 ${depvar}
  4. 
. sum `x'_uhat1 `x'_uhat2 `x'_uhat3
  5. di "==========================================================================="
  6. }

--------------------------------------------------
    Variable | regress_1   regress_2   regress_3  
-------------+------------------------------------
         age |    -0.000      -0.001      -0.002  
        wage |    -0.015      -0.014              
    military |    -0.321      -0.315      -0.500  
        race |    -0.065      -0.069      -0.068  
     mz_wage | (omitted)   (omitted)              
 mz_military | (omitted)   (omitted)   (omitted)  
    employed |             (omitted)      -0.079  
 mz_employed |             (omitted)   (omitted)  
       _cons |     0.922       0.941       0.870  
-------------+------------------------------------
           N |      2694        2647        4968  
          ll |  -1725.51    -1692.62    -3442.51  
        r2_p |                                    
        mrse |                                    
--------------------------------------------------

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
regress_yh~1 |      2,694    .5293244    .1958584  -.5876917   .8280627
regress_yh~2 |      2,647    .5255006    .1975194  -.5919468    .830496
regress_yh~3 |      4,968    .5933977    .0847209  -.0699391   .7666792
        unin |      7,892          .5    .5000317          0          1

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
regress_uh~1 |      7,892    .0056765       .0086          0   .0845468
regress_uh~2 |      7,892    .0056211    .0086307          0   .0858218
regress_uh~3 |      7,892    .0083874    .0070387          0   .0356136
===========================================================================

--------------------------------------------------
    Variable |  logit_1     logit_2     logit_3   
-------------+------------------------------------
         age |     0.002       0.000      -0.009  
        wage |    -0.099      -0.098              
    military | (omitted)   (omitted)   (omitted)  
        race |    -0.312      -0.327      -0.284  
     mz_wage | (omitted)   (omitted)              
 mz_military | (omitted)   (omitted)   (omitted)  
    employed |             (omitted)      -0.341  
 mz_employed |             (omitted)   (omitted)  
       _cons |     2.296       2.390       1.558  
-------------+------------------------------------
           N |      2690        2643        4964  
          ll |  -1601.07    -1570.02    -3281.25  
        r2_p |      0.14        0.14        0.02  
        mrse |                                    
--------------------------------------------------

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
 logit_yhat1 |      2,690    .5301115    .2073602   .0007035   .8672084
 logit_yhat2 |      2,643    .5262959    .2090418   .0006835    .868744
 logit_yhat3 |      4,964    .5938759    .0831398   .3222429    .754966
        unin |      7,892          .5    .5000317          0          1

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
 logit_uhat1 |      7,892    .0323035    .0546178          0   .4564077
 logit_uhat2 |      7,892    .0321159    .0549611          0   .4593498
 logit_uhat3 |      7,892    .0359749    .0302434          0   .1127057
===========================================================================

--------------------------------------------------
    Variable | probit_1    probit_2    probit_3   
-------------+------------------------------------
         age |     0.001      -0.000      -0.006  
        wage |    -0.057      -0.057              
    military | (omitted)   (omitted)   (omitted)  
        race |    -0.191      -0.200      -0.178  
     mz_wage | (omitted)   (omitted)              
 mz_military | (omitted)   (omitted)   (omitted)  
    employed |             (omitted)      -0.209  
 mz_employed |             (omitted)   (omitted)  
       _cons |     1.385       1.441       0.966  
-------------+------------------------------------
           N |      2690        2643        4964  
          ll |  -1603.37    -1572.20    -3280.79  
        r2_p |      0.14        0.14        0.02  
        mrse |                                    
--------------------------------------------------

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
probit_yhat1 |      2,690     .531175    .2039881   .0000112   .8682685
probit_yhat2 |      2,643    .5274384    .2057657   .0000104   .8703582
probit_yhat3 |      4,964    .5942951    .0834356   .3219967   .7572902
        unin |      7,892          .5    .5000317          0          1

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
probit_uhat1 |      7,892    .0194049     .032706          0   .2706423
probit_uhat2 |      7,892    .0192578    .0328226          0   .2712948
probit_uhat3 |      7,892    .0221587    .0185777          0   .0696867
===========================================================================

. 
. 
. local list = "regress logit probit"

. 
. forval y = 1/3 {
  2. foreach x in `list' {
  3.         
.                 estimates restore `x'_`y'
  4.                 
.                 noisily di "============================================================"
  5.                 noisily di "Model `x'_`y' " e(cmdline)
  6.                 noisily di "============================================================"
  7. 
.                 count if `x'_yhat`y' > .5 & ${depvar}==1 & e(sample)
  8.                 scalar x = r(N)
  9.                 count if ${depvar}==1 & e(sample)
 10.                 scalar y = r(N)
 11.                 scalar z1 = x/y
 12.                 noisily di "Correct Success Prediction Rate: " z1
 13.                 noisily di "predicted =" x ", Actual = " y
 14. 
.                 noisily di "  "
 15. 
.                 count if `x'_yhat`y'<.5 & ${depvar}==0 & e(sample)
 16.                 scalar x = r(N)
 17.                 count if ${depvar}==0 & e(sample) 
 18.                 scalar y = r(N)
 19.                 scalar z2 = x/y
 20.                 noisily di "Correct Failure Prediction Rate: " z2
 21.                 noisily di "predicted =" x ", Actual = " y
 22. 
.                 noisily di " "
 23.                 
.                 count if `x'_yhat`y'> .5 & ${depvar}==0 & e(sample)
 24.                 scalar x = r(N)
 25.                 count if ${depvar}==1 & e(sample)
 26.                 scalar y = r(N)
 27.                 scalar z3 = x/y
 28.                 noisily di "Incorrect Success Prediction Rate: " z3
 29.                 noisily di "predicted =" x ", Actual = " y
 30. 
.                 noisily di " "
 31.                 
.                 count if `x'_yhat`y'<.5 & ${depvar}==1 & e(sample)
 32.                 scalar x = r(N)
 33.                 count if ${depvar}==0 & e(sample)
 34.                 scalar y = r(N)
 35.                 scalar z4 = x/y
 36.                 noisily di "Incorrect Failure Prediction Rate: " z4
 37.                 noisily di "predicted =" x ", Actual = " y
 38.                 matrix define prediction`x'`y' = (z1, z2, z3, z4)
 39. 
. di "==========================================================================="
 40. }
 41. }
(results regress_1 are active now)
============================================================
Model regress_1 regress unin age wage military race mz_wage mz_military , robust 
============================================================
  1,186
  1,426
Correct Success Prediction Rate: .83169705
predicted =1186, Actual = 1426
  
  613
  1,268
Correct Failure Prediction Rate: .48343849
predicted =613, Actual = 1268
 
  655
  1,426
Incorrect Success Prediction Rate: .45932679
predicted =655, Actual = 1426
 
  240
  1,268
Incorrect Failure Prediction Rate: .18927445
predicted =240, Actual = 1268
===========================================================================
(results logit_1 are active now)
============================================================
Model logit_1 logit unin age wage military race mz_wage mz_military , robust 
============================================================
  1,147
  1,426
Correct Success Prediction Rate: .80434783
predicted =1147, Actual = 1426
  
  726
  1,264
Correct Failure Prediction Rate: .57436709
predicted =726, Actual = 1264
 
  538
  1,426
Incorrect Success Prediction Rate: .3772791
predicted =538, Actual = 1426
 
  279
  1,264
Incorrect Failure Prediction Rate: .22072785
predicted =279, Actual = 1264
===========================================================================
(results probit_1 are active now)
============================================================
Model probit_1 probit unin age wage military race mz_wage mz_military , robust 
============================================================
  1,144
  1,426
Correct Success Prediction Rate: .80224404
predicted =1144, Actual = 1426
  
  716
  1,264
Correct Failure Prediction Rate: .5664557
predicted =716, Actual = 1264
 
  548
  1,426
Incorrect Success Prediction Rate: .38429173
predicted =548, Actual = 1426
 
  282
  1,264
Incorrect Failure Prediction Rate: .22310127
predicted =282, Actual = 1264
===========================================================================
(results regress_2 are active now)
============================================================
Model regress_2 regress unin age wage military race employed mz_wage mz_employed mz_military , robust 
============================================================
  1,156
  1,391
Correct Success Prediction Rate: .83105679
predicted =1156, Actual = 1391
  
  643
  1,256
Correct Failure Prediction Rate: .51194268
predicted =643, Actual = 1256
 
  613
  1,391
Incorrect Success Prediction Rate: .44069015
predicted =613, Actual = 1391
 
  235
  1,256
Incorrect Failure Prediction Rate: .18710191
predicted =235, Actual = 1256
===========================================================================
(results logit_2 are active now)
============================================================
Model logit_2 logit unin age wage military race employed mz_wage mz_employed mz_military , robust 
============================================================
  1,094
  1,391
Correct Success Prediction Rate: .78648454
predicted =1094, Actual = 1391
  
  727
  1,252
Correct Failure Prediction Rate: .58067093
predicted =727, Actual = 1252
 
  525
  1,391
Incorrect Success Prediction Rate: .37742631
predicted =525, Actual = 1391
 
  297
  1,252
Incorrect Failure Prediction Rate: .23722045
predicted =297, Actual = 1252
===========================================================================
(results probit_2 are active now)
============================================================
Model probit_2 probit unin age wage military race employed mz_wage mz_employed mz_military , robust 
============================================================
  1,099
  1,391
Correct Success Prediction Rate: .79007908
predicted =1099, Actual = 1391
  
  721
  1,252
Correct Failure Prediction Rate: .57587859
predicted =721, Actual = 1252
 
  531
  1,391
Incorrect Success Prediction Rate: .38173976
predicted =531, Actual = 1391
 
  292
  1,252
Incorrect Failure Prediction Rate: .23322684
predicted =292, Actual = 1252
===========================================================================
(results regress_3 are active now)
============================================================
Model regress_3 regress unin age military race employed mz_employed mz_military , robust 
============================================================
  2,582
  2,948
Correct Success Prediction Rate: .87584803
predicted =2582, Actual = 2948
  
  315
  2,020
Correct Failure Prediction Rate: .15594059
predicted =315, Actual = 2020
 
  1,705
  2,948
Incorrect Success Prediction Rate: .57835821
predicted =1705, Actual = 2948
 
  366
  2,020
Incorrect Failure Prediction Rate: .18118812
predicted =366, Actual = 2020
===========================================================================
(results logit_3 are active now)
============================================================
Model logit_3 logit unin age military race employed mz_employed mz_military , robust 
============================================================
  2,583
  2,948
Correct Success Prediction Rate: .87618725
predicted =2583, Actual = 2948
  
  311
  2,016
Correct Failure Prediction Rate: .15426587
predicted =311, Actual = 2016
 
  1,705
  2,948
Incorrect Success Prediction Rate: .57835821
predicted =1705, Actual = 2948
 
  365
  2,016
Incorrect Failure Prediction Rate: .18105159
predicted =365, Actual = 2016
===========================================================================
(results probit_3 are active now)
============================================================
Model probit_3 probit unin age military race employed mz_employed mz_military , robust 
============================================================
  2,582
  2,948
Correct Success Prediction Rate: .87584803
predicted =2582, Actual = 2948
  
  311
  2,016
Correct Failure Prediction Rate: .15426587
predicted =311, Actual = 2016
 
  1,705
  2,948
Incorrect Success Prediction Rate: .57835821
predicted =1705, Actual = 2948
 
  366
  2,016
Incorrect Failure Prediction Rate: .18154762
predicted =366, Actual = 2016
===========================================================================

. 
. 
. 
. forval y = 1/3 {
  2.         matrix accuracy`y' = (predictionregress`y' \ predictionlogit`y' \ predictionprobit`y')
  3.         matrix colnames accuracy`y' = correct_success correct_failure   inaccurate_success inaccurate_failure
  4.         matrix rownames accuracy`x'`y' = REGRESS LOGIT PROBIT
  5.         putexcel set "prediction2.csv", sheet(robust`y') modify
  6.         putexcel A1 = matrix(accuracy`x'`y'), names nformat(number_d2)
  7. 
. }
file prediction2.csv saved
file prediction2.csv saved
file prediction2.csv saved

. 
end of do-file

. save "C:\Users\rayde\Downloads\h196dat\final_paper.dta"
file C:\Users\rayde\Downloads\h196dat\final_paper.dta saved

. exit
